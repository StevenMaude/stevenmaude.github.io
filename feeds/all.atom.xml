<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>stevenmaude.co.uk</title><link href="https://www.stevenmaude.co.uk/" rel="alternate"></link><link href="https://www.stevenmaude.co.uk/feeds/all.atom.xml" rel="self"></link><id>https://www.stevenmaude.co.uk/</id><updated>2023-04-02T14:23:00+01:00</updated><entry><title>"Docs Like Code": a book review</title><link href="https://www.stevenmaude.co.uk/posts/docs-like-code-a-book-review" rel="alternate"></link><published>2023-04-02T14:23:00+01:00</published><updated>2023-04-02T14:23:00+01:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2023-04-02:/posts/docs-like-code-a-book-review</id><summary type="html">&lt;p&gt;A review of "Docs Like Code" by Anne Gentle, and some thoughts on docs as code&lt;/p&gt;</summary><content type="html">&lt;h2 id="what-is-docs-as-code-anyway"&gt;What is "docs as code" anyway?&lt;/h2&gt;
&lt;p&gt;The book "Docs Like Code" covers the approach of treating software
documentation just as the code that it documents. This approach to often
referred to as "documentation as code" or "docs as code".&lt;/p&gt;
&lt;p&gt;It seems that "docs as code" is the more common description. But,
whether intentional or not, the "like" in "docs like code" could also be
considered a pun. That is, not just treating your documentation like
code, but your documentation "liking" code, being handled in the same
way and sometimes in the same repository.&lt;/p&gt;
&lt;p&gt;What is meant by treating software documentation as code is that you use
the same kinds of tools, processes and workflows to work on your
documentation, as software developers do when working on code.&lt;/p&gt;
&lt;p&gt;This might include some or all of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;use of a version control system&lt;/li&gt;
&lt;li&gt;collaboration via an online code hosting service&lt;/li&gt;
&lt;li&gt;writing documentation in a markup language&lt;/li&gt;
&lt;li&gt;using a static site generator to build the documentation&lt;/li&gt;
&lt;li&gt;automated checks on the documentation before changes are included to
  the main documentation version&lt;/li&gt;
&lt;li&gt;manual review on changes proposed for inclusion in the main
  documentation version&lt;/li&gt;
&lt;li&gt;automatic documentation build and deployment once new changes are made
  to the main documentation version&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sometimes approaches to solving technical problems can be pushed with a
very prescriptive, dogmatic approaches: do this, use that, do not do
this, why are you using &lt;em&gt;that&lt;/em&gt;? From what I have seen, one refreshing,
feature of docs as code is that it is not particularly prescriptive
about the &lt;em&gt;specific&lt;/em&gt; tools that you use. Nor does docs as code say how
much of the tooling you need to adopt.&lt;/p&gt;
&lt;p&gt;In some cases, tooling choices might be almost predetermined by
overwhelming popularity: for instance, you can use any version control
system for docs as code, but it is likely that people right now will
choose Git. But this is still left to you to decide for your own case.&lt;/p&gt;
&lt;p&gt;Even if you do not intend to adopt a full docs as code approach for
writing documentation, you might benefit adopting some of the closely
associated tooling. For example, you could still run tools like link,
style and spell checkers against your documentation source, even outside
of using version control or automated checks.&lt;/p&gt;
&lt;h2 id="edition-recognition"&gt;Edition recognition&lt;/h2&gt;
&lt;p&gt;I actually bought the second edition of this book to read through prior
to giving a talk in 2022 on documentation. I skimmed it, realised that
some of it was understandably outdated seeing given it was published
five years before. On looking again very recently, I found the third
edition, and decided to revisit the book. As it turns out, &lt;em&gt;obviously&lt;/em&gt;,
the third edition of course got published about a week after I bought
the second edition.&lt;/p&gt;
&lt;p&gt;Having just bought and read the third edition, it does generally seem
up-to-date. There was nothing I read that felt like it was giving advice
that was once appropriate, but no longer.&lt;/p&gt;
&lt;p&gt;Skimming through the second edition for comparison, it seems like the
main differences are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the book has generally been expanded a little; particularly on
  building and testing documentation&lt;/li&gt;
&lt;li&gt;there was a tutorial in the second edition that has been perhaps
  sensibly removed for the third edition, given that tutorials can date
  quite quickly&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="what-the-book-covers"&gt;What the book covers&lt;/h2&gt;
&lt;p&gt;The book has three core chapters and a final chapter summary. The first
chapter describes the benefits of adopting a docs as code approach,
summarising why the kinds of tools I listed above are useful.&lt;/p&gt;
&lt;p&gt;The second chapter details what you might consider when deciding to
apply docs as code to a project: from requirements, to thinking about
the tools you might use, and how you might organise repositories.&lt;/p&gt;
&lt;p&gt;The final core chapter describes some of the features of working on docs
as code projects. You need to think about how to make it easy for
contributors to work on the documentation, how changes are incorporated
into the repository, how to review and approve those changes, how you
will publish and release, and how you use automated tooling to help with
tasks.&lt;/p&gt;
&lt;p&gt;Although the book is written from the perspective of practitioners who
have applied docs as code in enterprise projects, the book is not overly
sanguine. Some of the challenges of docs as code are also described:
getting adoption from a wider team, that is both from developers who may
not feel like documentation is their responsibility, and writers who may
be less comfortable using a different, and perhaps more complicated, set
of authoring tools than they are used to.&lt;/p&gt;
&lt;p&gt;Quite rightly, the authors highlight that working with Git and online
code hosting platforms like GitHub has a considerable learning barrier
to overcome for new users. Certainly, once you &lt;em&gt;do&lt;/em&gt; feel a little bit
more comfortable with Git, it is easy to forget how much of a struggle
it is when you start out, with several opaque and mysterious commands
that you need to know.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id="a-few-small-criticisms"&gt;A few small criticisms&lt;/h2&gt;
&lt;p&gt;While I did not generally disagree with anything I was reading, I did
feel like the book could have done with another proofread. I probably
would not be so picky, but the authors&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt; are technical writers by
trade.&lt;/p&gt;
&lt;p&gt;Some presentational examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there is one particularly horrendous bit of word spacing over a couple
  of sentences where all the words just run into each other&lt;/li&gt;
&lt;li&gt;there are a few footnotes that are then immediately and pointlessly
  duplicated&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There were also a couple of small technical points that I queried as
reading: for example, the claim that Ruby:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;predates Python by about four years&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Perhaps the authors just got the two mixed up. From reading around, it
seems that this is the other way around, as I instinctively thought,
with Python being older.&lt;/p&gt;
&lt;p&gt;Finally, glossaries are included as part of the main text and this feel
incongruous, particularly early on in the text. In the second edition,
the glossary was included at the end, which feels less daunting than
throwing lots of Git jargon at the reader, when the reader probably does
not really need it to understand most of the book. The authors do remark
that the book is not intended to teach the reader about Git or GitHub.&lt;/p&gt;
&lt;p&gt;These are all relatively small complaints, however, and do not really
detract from the book itself.&lt;/p&gt;
&lt;h2 id="origins-of-docs-as-code"&gt;Origins of docs as code&lt;/h2&gt;
&lt;p&gt;As mentioned, the authors seem to have a technical writing background.
Without researching it, my hunch would be that some of where the push
for docs as code has come from is more from technically skilled writers,
more so than for developers, and some of those realising that they could
use the same tools as developers. That is my personal guess: the book
does not actually give much of a history of who actually originated the
idea of docs as code. Instead, a timeline of major organisations
proclaiming public support for the docs as code approach is given.&lt;/p&gt;
&lt;p&gt;These origins might also explain the lack of dogmatism around what you
should and should not do that I alluded to above.&lt;/p&gt;
&lt;p&gt;Even without knowing that docs as code is a described concept, I suspect
that developers would naturally favour a docs as code approach for
documentation, if developers were given a choice in the isolation of any
external considerations or requirements. It is a natural extension of
how developers often work: developers routinely work in a repository,
collaborate on code hosting platforms, and often implement automation of
checks, builds and releases.&lt;/p&gt;
&lt;p&gt;Personally, I even write collections of notes and writing in plain text
markup and store in Git repositories, even when the intent is to just
collate that text, without any further publication. Creating and working
on Git repositories is a quick and powerful process, once you are
accustomed to it.&lt;/p&gt;
&lt;h2 id="where-next"&gt;Where next?&lt;/h2&gt;
&lt;p&gt;The authors do also quite rightly point out that docs as code is an
approach that can be at least considered at all scales. It is as valid
to consider for single developers maintaining their own software, as it
is for much larger organisations working on bigger collaborative
projects. Because this is a flexible approach, and one that can gel well
with developers working on code, it does seem likely that it will
continue to persist and gain increased adoption and recognition.&lt;/p&gt;
&lt;p&gt;Though I did not learn much new from the book, I am perhaps not the most
appropriate audience — the authors recommend it for technical writers
and ther managers. My reading was still useful to be reassured that lots
of ideas that I have learned from various places, without much formal
training, are not incongruent with those of people who do primarily work
on documentation.&lt;/p&gt;
&lt;p&gt;Though the book seems a good summary of where docs as code is right now,
what is not mentioned is much of where the authors anticipate future
trends. They do allude to artificial intelligence and machine learning
tools being used as auxiliary supporting helpers when writing. With the
rate that large language models are developing, and finding application,
it does not seem unreasonable that this might be a considerable shift in
the near future.&lt;/p&gt;
&lt;p&gt;One of the barriers for the uses of large language models is that what
they output does not always necessarily make sense, or may be
inaccurate. But writing usually involves editing as a central part of
the process. Adoption of automated tools here, when you anticipate
editing regardless of where the author's material originate, seems a
natural fit. One of the interesting conclusions from Hannah Fry's "Hello
World" is that automated tools may be particularly valuable to do
tedious work or heavy lifting, but are likely to be particularly useful
when used in partnership with humans. This seems like it could be the
case for future writing.&lt;/p&gt;
&lt;p&gt;What that means for docs as code is that the integration of code with
documentation — where code is actually aiding a considerable part of the
authoring of documentation — may become even closer.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;I think the Git developers have made some efforts to make its
  interface more consistent, but I suspect the initial barrier to
  learning is still there. Whether tools like GitHub Desktop can help
  here, I am not sure. Really, the problem is that having an
  understanding of how Git functions is helpful to be able to use it,
  and there are several concepts you need to learn at once.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Why "authors"? Strangely, there are three listed authors in the
  third edition, including the named author. In the second edition, two
  of the third edition's authors are listed as contributors. In any
  case, I have used the plural.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="2023"></category><category term="documentation"></category><category term="docs as code"></category></entry><entry><title>Adjustable height standing desks in small spaces</title><link href="https://www.stevenmaude.co.uk/posts/adjustable-height-standing-desks-in-small-spaces" rel="alternate"></link><published>2023-02-10T22:26:00+00:00</published><updated>2023-02-10T22:26:00+00:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2023-02-10:/posts/adjustable-height-standing-desks-in-small-spaces</id><summary type="html">&lt;p&gt;Notes on installing a Fully Jarvis desk in a small corner space.&lt;/p&gt;</summary><content type="html">&lt;h2 id="a-new-desk"&gt;A new desk&lt;/h2&gt;
&lt;p&gt;I am standing up while typing this with my computer and keyboard resting
on a new desk. My previous desk — a cheap, but value for money, IKEA
effort — has been swapped for a Fully Jarvis adjustable height frame
with a custom desktop.&lt;/p&gt;
&lt;p&gt;When I used to actually go into an office, there used to be rudimentary,
but functional standing desk setups, based on an IKEA hack of using a
side table placed on top of the standard office desks when you wanted to
stand and work. I actually enjoyed doing that when I was in the office
as I was in the office a couple of days a week. The Fully Jarvis goes
further than that. It has height adjustment, so you can switch between
sitting and standing at the desk.&lt;/p&gt;
&lt;p&gt;I will discuss the Jarvis frame here. What I will not cover here are the
pros and cons of standing versus sitting. But when using a computer for
a lot of the working day, even not considering anything else, it seems a
positive feature to be able to change posture and not just languish in
the same working position for several hours of the day.&lt;/p&gt;
&lt;h3 id="limited-space"&gt;Limited space&lt;/h3&gt;
&lt;p&gt;One problem: I did not have too much space in the corner the desk is now
sat. This made it trickier to ascertain whether a Jarvis desk would
work. Lots of people with standing desk setups seem to be going for
large desks. There was very little useful guidance online about what
would work in a smaller space.&lt;/p&gt;
&lt;p&gt;In this post, I will note some of the considerations I had, and what I
found from the process of buying and installing the frame and desktop in
a smaller space.&lt;/p&gt;
&lt;h2 id="some-notes-on-standing-desks-for-small-spaces"&gt;Some notes on standing desks for small spaces&lt;/h2&gt;
&lt;p&gt;Like just about everything else, there are a lot of opinions on standing
desks out there. However, much like the limited range of desks that are
out there to fit a small space, there are relatively few opinions on
desks for small spaces.&lt;/p&gt;
&lt;h3 id="what-is-out-there"&gt;What is out there?&lt;/h3&gt;
&lt;p&gt;Many desks and separate desktops seem to start at a minimum of 120 cm by
70 cm. 140 cm by 70 cm is another common size. Both of these were
considerably bigger than the existing desk I was using: 100 cm by 60 cm.
The desktops bundled by Fully with the Jarvis frame are even larger: 80
cm deep.&lt;/p&gt;
&lt;p&gt;There were occasionally standing desks that I found at a more suitable
100 cm by 60 cm, but often they all looked like they were from the same
or similar suppliers: frequently having a ridge in the middle of the
desk. That did not look great, and I thought it might be fairly
irritating if using the desk to rest on while writing.&lt;/p&gt;
&lt;p&gt;So, given most desktops are too large, then the next step is to consider
getting a custom size cut. If you have the tools and the competence,
then you could do this yourself.&lt;/p&gt;
&lt;p&gt;I have neither.&lt;/p&gt;
&lt;p&gt;Even if I did, there is also the problem of getting a huge worktop home,
which may well need you to pay an extra delivery cost, unless you happen
to have a large van handy.&lt;/p&gt;
&lt;p&gt;IKEA do offer custom sizes on some of their desktops, but these, from
memory, may work out actually more expensive for less material than the
fixed sizes they offer. The store I visited also had a lead time of
about a month too, which was far from ideal. Fully have a fairly
generous 30 day trial period, and I wanted to try out the frame in that
time to be sure it was right. A month's wait for a desktop would have
probably given insufficient time to actually build the desk up.&lt;/p&gt;
&lt;p&gt;I also looked at local timber merchants but these were fairly expensive.&lt;/p&gt;
&lt;p&gt;In the end, I read a suggestion from someone who said they had used a
Kabsa kitchen worktop from &lt;a href="https://en.wikipedia.org/wiki/B%26Q"&gt;B&amp;amp;Q&lt;/a&gt; —
a fairly common building materials supplier in the UK, and mentioned
that B&amp;amp;Q cut the worktop to size, free of charge. I had also read that
someone had used a kitchen worktop with a Jarvis frame and they said it
was fine.&lt;/p&gt;
&lt;h3 id="buying-from-bq"&gt;Buying from B&amp;amp;Q&lt;/h3&gt;
&lt;p&gt;Before you start thinking, "are you doing paid promotions for niche UK
retailers now?", &lt;em&gt;certainly not&lt;/em&gt;. What I will not into are the couple of
problems I had in actually getting hold of a worktop from B&amp;amp;Q and
getting it cut. In the end, after several visits, I did emerge,
victorious with a laminate worktop (less held up as a winner's trophy,
more pushed on a trolley to a car to load).&lt;/p&gt;
&lt;p&gt;Aside from the problems that will remain unmentioned here, there are a
few things to watch out for with B&amp;amp;Q:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check the store has a timber cutting service: not all do.&lt;/li&gt;
&lt;li&gt;The laminate worktops have a variety of surfaces. Some are smoother,
  while some have a rougher grain feeling to them. There are samples in
  store that you can check first.&lt;/li&gt;
&lt;li&gt;The worktops, at least in the store I visited, were simply only in
  thick plastic film, without any decent protection. Yes, this meant you
  could easily see the worktops, but also meant that almost half of the
  worktops of the kind I wanted were already damaged.&lt;/li&gt;
&lt;li&gt;B&amp;amp;Q sell edging tape that closely matches many of the worktops, but
  perhaps it is best to check that they have it in stock before
  committing to a worktop purchase.&lt;/li&gt;
&lt;li&gt;There is a limit to the number of free timber cuts B&amp;amp;Q offer, but for
  a worktop, you probably do not need more than one or two cuts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On the positive side, and, no, this is still not a paid promotion, the
staff cutting the worktop to size were helpful, and provided a tape
measure for me to verify the cut size was correct before paying.&lt;/p&gt;
&lt;p&gt;As well as being easier to get into a car. The other advantage of a
smaller cut is that from a 3 metre long worktop, I got two pieces to use
from it, in case the initial assembly was a disaster.&lt;/p&gt;
&lt;h3 id="desktop-fit-on-the-jarvis-frame"&gt;Desktop fit on the Jarvis frame&lt;/h3&gt;
&lt;p&gt;The Jarvis frame assembly is relatively simple, marred by the paper
instructions being a little bit vague and the official assembly video
being a little bit too brief, and not covering custom desktops. The
bundled paper instructions did not cover custom desktops either. There
is an &lt;a href="https://static.fully.com/image/upload/v1637081801/fully-website/product/jarvis-desk/AI/EU/fully-jarvis-wide-using-your-own-desktop-EU-d03.pdf"&gt;additional instruction guide supplement on the Fully
website&lt;/a&gt;,
but this is not especially obvious. I am not sure why Fully could not
provide the extra few pages of instructions in the standard assembly
guide.&lt;/p&gt;
&lt;p&gt;There was one &lt;a href="https://www.youtube.com/watch?v=6NFmOZphHPM"&gt;YouTube
guide&lt;/a&gt; that was
particularly useful on assembling the frame with a custom desktop. It is
definitely worth watching through once, and then unpacking the Jarvis
boxes and then starting to figure out what you need to do.&lt;/p&gt;
&lt;p&gt;The trickiest part was measuring the holes for the desktop screws. When
placing the frame upside down on the underside of the desktop and
holding it together, you will find that the frame tends to move around a
little (which, &lt;em&gt;obviously&lt;/em&gt; it does, because nothing is screwed together
yet). This makes it more difficult to mark the holes. I ended up
measuring and re-checking the proposed hole positions several times.&lt;/p&gt;
&lt;p&gt;From memory, I think that the holes did not need drilling first. The
screws just went straight into the worktop with an electric screwdriver.&lt;/p&gt;
&lt;p&gt;A couple of questions that I had during assembly, that luckily had the
right answer:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do Fully provide screws for custom worktops? &lt;em&gt;Yes.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Would the worktop I bought be the correct thickness for the frame and
  the screws? &lt;em&gt;Yes.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After doubly checking everything was screwed together and turning the
frame over, everything seemed to be just fine. A considerable relief
considering the cost of the frame.&lt;/p&gt;
&lt;p&gt;Once the desk was assembled, the unfinished three worktop edges were
covered with the matching edging tape that I had bought. The edges were
stuck to the desktop with EVO-STIK Impact Contact Adhesive from a tin: a
frequent recommendation reading around responses to people working on
finishing kitchen worktop installations.&lt;/p&gt;
&lt;h4 id="desktop-specifications"&gt;Desktop specifications&lt;/h4&gt;
&lt;h5 id="jarvis-frame"&gt;Jarvis frame&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;I chose the 3-stage frame, for the extra variation in height
  adjustment, particularly for sitting.&lt;/li&gt;
&lt;li&gt;The frame I have is the alloy colour, which actually looks a lighter
  silver than the duller, colder looking image shown on the Fully site
  when ordering.&lt;/li&gt;
&lt;li&gt;I also paid the extra for the programmable memory control panel
  upgrade. It is well worth it, as it does not add much to the cost, but
  makes adjusting the desk much quicker.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id="worktop"&gt;Worktop&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;B&amp;amp;Q's kitchen worktops are typically around 62 cm deep, which is not
  exactly a standard desk size. But, it does seem to be roughly the
  standard size for kitchen worktops in the UK, though that can be as
  small as 60 cm. In any case, the depth is a few centimetres less than
  Fully's minimum recommended 69 cm for the Jarvis frame. But, when
  assembled, the table feet do not particularly stick out, and the frame
  does not seem less stable for the smaller desktop.&lt;/li&gt;
&lt;li&gt;I went for a very slightly wider desktop (112 cm) than the minimum
  suggested by Fully (108 cm). You could probably go all the way to the
  minimum specified size, but it would be a tight fit. Having the couple
  of extra centimetres leeway from the frame to the desktop edge was
  useful.&lt;/li&gt;
&lt;li&gt;As mentioned, a moderately thick desktop (38 mm) works fine, and can
  have a nice sturdy and weighty feel to it. At least, my particle board
  laminate worktop did.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="what-do-i-think"&gt;What do I think?&lt;/h2&gt;
&lt;p&gt;Overall, I am pretty happy with the result, given that the top is a
custom build. Someone who did not know that it was a kitchen worktop
could easily mistake it for the desktop that is sold with the frame.&lt;/p&gt;
&lt;p&gt;The frame is also reasonably wobble-free, even at standing height, which
was my other concern. A concern that you cannot easily address without
just building the desk in your own space and trying it. When typing, the
desk does not move, which is what I wanted.&lt;/p&gt;
&lt;p&gt;That positive impression is tempered very slightly by the sheer cost of
the frame: the best part of £500. And then tempered back to positive
again when I remember that I have not paid for the frame at all. No,
this is not a paid promotion for Fully either. I was fortunate enough to
get one of my &lt;a href="https://sensiblecode.io"&gt;employers&lt;/a&gt; to cover it in their
homeworking equipment budget. Thanks also to &lt;a href="https://github.com/mikejamesthompson"&gt;my colleague
Mike&lt;/a&gt; at Sensible Code, who
recommended the frame when I asked about it.&lt;/p&gt;
&lt;p&gt;Fully have been around for a while and do have generally positive
feedback, from what I have read, for their customer service. I did
interact with them briefly and they were very helpful. There are other,
considerably cheaper brands of adjustable height standing desks, but
some of these appeared to have mixed reviews, often with the complaint
that support was non-existent when the desks became faulty. On that,
Fully do also offer a decent length of warranty on their frames.&lt;/p&gt;
&lt;p&gt;Finally, Fully do seem to have fairly regular discounts. If you are not
buying in a hurry, it is worth watching the price and holding out.&lt;/p&gt;</content><category term="2023"></category><category term="standing desk"></category><category term="Fully"></category><category term="Jarvis"></category></entry><entry><title>Migrating a Bitlocker Windows installation to a larger drive</title><link href="https://www.stevenmaude.co.uk/posts/migrating-a-bitlocker-windows-installation-to-a-larger-drive" rel="alternate"></link><published>2023-01-02T23:33:00+00:00</published><updated>2023-01-02T23:33:00+00:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2023-01-02:/posts/migrating-a-bitlocker-windows-installation-to-a-larger-drive</id><summary type="html">&lt;p&gt;How to clone a Windows installation to another disk&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently cloned a Windows 10 installation's Bitlocker encrypted drive
to upgrade a PC's solid state drive (SSD) from a smaller SATA drive to
an NVMe drive. Here are thorough notes on what I did if you need to do
the same.&lt;/p&gt;
&lt;p&gt;The Bitlocker aspect doesn't actually seem to make much difference here.
This is the same process you could to clone an unencrypted Windows disk,
but it's worth noting that this does work for Bitlocker-encrypted disks.&lt;/p&gt;
&lt;h2 id="caveat"&gt;Caveat&lt;/h2&gt;
&lt;p&gt;This upgrade ostensibly seemed to work fine.&lt;/p&gt;
&lt;p&gt;However, with the cloned drive, the Windows Mail app required
reinstallation as it wouldn't load. From reading around, there can be
some weirdness around Universal Windows Platform (UWP) applications.
Right now, I can't find any specific fix outside of reinstalling those
affected apps. In this case, reinstalling the Mail app seemed to work,
and had retained all the existing data. That aside, other UWP apps
seemed to work on the machine, so I don't know. I love computers very
much.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do be prepared if you have lots of UWP apps&lt;/strong&gt;: you might still need to
reinstall them though. I couldn't find any other workaround, but only
looked for a few minutes.&lt;/p&gt;
&lt;h2 id="upgrade-process"&gt;Upgrade process&lt;/h2&gt;
&lt;p&gt;For this kind of installation, I typically write out step-by-step what I
intend to do first, so I'm less likely to miss a step or forget
something. Ultimately, the process as it turned out didn't differ that
much from what I sketched out at first.&lt;/p&gt;
&lt;p&gt;Of course, there was one issue I didn't anticipate: there was a Windows
recovery partition at the end of the original drive. This meant that the
free space after upgrading was not contiguous with the existing Windows
volume: the recovery partition was in the way, preventing the volume
from expanding to fill the drive. To fix this, I had to move the Windows
recovery partition to the end of the newer, larger drive, so that the
existing Bitlocker volume could be expanded by the Windows Disk
Management tool. &lt;a href="https://superuser.com/questions/1453790/how-to-move-the-recovery-partition-on-windows-10"&gt;This Super User
question&lt;/a&gt;
helped solve that problem, and &lt;a href="https://superuser.com/a/1637944"&gt;this
answer&lt;/a&gt; is used as the basis for some
of this guide.&lt;/p&gt;
&lt;p&gt;Below are my corrected notes after completing the upgrade, broken into
four sections. It's worth reading through the whole set of instructions
first. These aren't completely exhaustive, but should be enough to get
you to what you need.&lt;/p&gt;
&lt;h3 id="preparation"&gt;Preparation&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Backup the old drive entirely first, before starting the upgrade. The
   likelihood of disaster may be small, but the impact of that is high
   if you have no backup. So, &lt;strong&gt;backup&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Ensure you have the Bitlocker recovery key and it works. I don't
   think you should need the recovery key for upgrading a drive in the
   same PC, but, again, best to check this before you start.&lt;/li&gt;
&lt;li&gt;Shutdown the PC, entirely powering it off. (I actually forgot to do
   this and hibernated, but this was also fine, provided the PC is
   powered off.)&lt;/li&gt;
&lt;li&gt;Open up the PC, install the new drive into the expansion slot inside
   the PC and close up the PC again.&lt;/li&gt;
&lt;li&gt;Update drive firmware if there is a update needed. You can try
   searching the manufacturer's site to see if an upgrade is available.
   Manufacturers don't always make this information easy to discover.
   You may just want to install whatever utility the manufacturer offers
   to check for firmware updates and update via that. (Most
   manufacturers have some kind of tool; a few provide updates via a
   bootable disk image.)&lt;/li&gt;
&lt;li&gt;Download a bootable Linux installation: &lt;a href="https://ubuntu.com"&gt;Ubuntu&lt;/a&gt;
   works fine and has all the tools you need.&lt;/li&gt;
&lt;li&gt;(Optional) Verify the download; there is a &lt;a href="https://ubuntu.com/tutorials/how-to-verify-ubuntu"&gt;guide for checking Ubuntu
   downloads&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Write that Linux image to a USB drive or DVD as a "live installation.&lt;/li&gt;
&lt;li&gt;(Optional) Verify that the Linux image has been written correctly:
   you can do this easily &lt;a href="https://unix.stackexchange.com/a/84474"&gt;if you're already running
   Linux&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="cloning-the-disk"&gt;Cloning the disk&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Boot the live Ubuntu installation from a USB or DVD. You'll probably
   need to enter the boot menu of your BIOS to select the USB or DVD to
   boot from. For Ubuntu booting via a DVD, you may want to add the
   custom boot parameter: &lt;code&gt;fsck.mode=skip&lt;/code&gt; to skip the integrity check
   as &lt;a href="https://bugs.launchpad.net/ubuntu/+source/casper/+bug/1875548"&gt;it is often very slow via
   DVD&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;(Optional) Wipe the newly installed drive. This may not be strictly
   be necessary if a new drive, but I tend to do this anyway. The Arch
   Linux wiki has lots of information on using the &lt;code&gt;hdparm&lt;/code&gt; (for SATA
   drives) and &lt;code&gt;nvme-cli&lt;/code&gt; (for NVMe drives) tools to do this. In the
   current Ubuntu release (22.04.1), the &lt;code&gt;nvme-cli&lt;/code&gt; tool is not
   installed, so you'll need to open a terminal and install it via &lt;code&gt;sudo
   apt update &amp;amp;&amp;amp; sudo apt install nvme-cli&lt;/code&gt;. You will run these commands
   in a terminal.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run some command to clone the drive. I went with running in a
   terminal: &lt;code&gt;sudo dd if=/dev/old-drive-device-name
   of=/dev/new-drive-device-name status=progress bs=32M; sync&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Use the &lt;code&gt;lsblk&lt;/code&gt; command to find the correct &lt;code&gt;old-drive-device-name&lt;/code&gt;
 and &lt;code&gt;new-drive-device-name&lt;/code&gt;. &lt;strong&gt;Triple check that you have the input
 (&lt;code&gt;if&lt;/code&gt;) and output (&lt;code&gt;of&lt;/code&gt;) files the correct way round&lt;/strong&gt; before
 running the command.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;bs&lt;/code&gt; controls the block size. The default block size is small,
 so we specify a larger one to speed up cloning the disk: the
 transfer rate was about 500 MB/s transfer rate, probably limited by
 the read speed of the SATA SSD drive.&lt;/p&gt;
&lt;p&gt;The final &lt;code&gt;sync&lt;/code&gt; is to ensure anything cached is written to the
 disk, although shutting Linux down via the shutdown option (as
 opposed to just powering off) as we'll do next should also ensure
 this.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shutdown Ubuntu entirely. Left click the mouse in the top-right of
   the screen where the volume icon is, and you'll see the power
   options.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="reorganising-the-disk-volumes"&gt;Reorganising the disk volumes&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Check the boot order in the BIOS and reorder it if necessary to
   prioritise the new drive over the old.&lt;/li&gt;
&lt;li&gt;Boot into Windows.&lt;/li&gt;
&lt;li&gt;In an command prompt as administrator, use Windows' &lt;a href="https://learn.microsoft.com/en-us/windows-hardware/manufacture/desktop/reagentc-command-line-options"&gt;REAgentC
   command&lt;/a&gt;
   to disable the Windows Recovery Environment temporarily: &lt;code&gt;reagentc
   /disable&lt;/code&gt; — you could optimise this and save a reboot by doing this
   in Windows before cloning.&lt;/li&gt;
&lt;li&gt;Shutdown Windows.&lt;/li&gt;
&lt;li&gt;Boot back into your Ubuntu live installation once again.&lt;/li&gt;
&lt;li&gt;Run the GParted graphical application. Move the Windows recovery
   partition to end of drive. You'll be prompted to fix the incorrect
   GPT record, which will be wrong due to the change in drive size. You
   need to do this otherwise moving the partition will fail. Apply the
   partition changes, which should now be successful.&lt;/li&gt;
&lt;li&gt;Shutdown Ubuntu again.&lt;/li&gt;
&lt;li&gt;Boot back into Windows.&lt;/li&gt;
&lt;li&gt;In an command prompt as administrator, run &lt;code&gt;reagentc /enable&lt;/code&gt; to
   enable the Windows Recovery Environment again.&lt;/li&gt;
&lt;li&gt;Run the Computer Management application as administrator, and go
    to Disk Management.&lt;/li&gt;
&lt;li&gt;Right click on the Bitlocker Windows volume, and select "Extend
    Volume" to fill the unused space.&lt;/li&gt;
&lt;li&gt;Check the properties of the newly expanded drive in Windows Explorer
    and confirm that the drive has a larger size.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="final-checks-and-cleaning-up"&gt;Final checks and cleaning up&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Boot into the &lt;a href="https://learn.microsoft.com/en-us/windows-hardware/manufacture/desktop/windows-recovery-environment--windows-re--technical-reference"&gt;Windows Recovery
   Environment&lt;/a&gt;
   to confirm that it works. It's also possible to boot to this directly
   with ReAgentC via &lt;a href="https://learn.microsoft.com/en-us/windows-hardware/manufacture/desktop/reagentc-command-line-options"&gt;&lt;code&gt;reagentc
   /boottore&lt;/code&gt;&lt;/a&gt;
   command.&lt;/li&gt;
&lt;li&gt;After you have checked the Windows recovery environment, reboot back
   into Windows.&lt;/li&gt;
&lt;li&gt;Via the Activation settings, check that Windows is still activated if
   it was activated previously. I didn't need to reactivate the PC in
   this case.&lt;/li&gt;
&lt;li&gt;Shutdown Windows.&lt;/li&gt;
&lt;li&gt;Open the PC, disconnect the old drive, and then remove the old drive
   from the PC.&lt;/li&gt;
&lt;/ol&gt;</content><category term="2023"></category><category term="Bitlocker"></category><category term="Windows"></category></entry><entry><title>Link checking with lychee</title><link href="https://www.stevenmaude.co.uk/posts/link-checking-with-lychee" rel="alternate"></link><published>2022-09-07T21:11:00+01:00</published><updated>2022-09-07T21:11:00+01:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2022-09-07:/posts/link-checking-with-lychee</id><summary type="html">&lt;p&gt;A rundown of validating URLs with lychee&lt;/p&gt;</summary><content type="html">&lt;h2 id="the-use-of-urls-in-writing"&gt;The use of URLs in writing&lt;/h2&gt;
&lt;p&gt;Lots of information these days is on the web. Here, you're looking at
some.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;And with that, this means that URLs, often in the form of links to web
content, are also heavily used in all kinds of writing: other web pages,
reports, papers, books.&lt;/p&gt;
&lt;p&gt;In some of those cases, writing is published and then largely "done",
unless there's a revised edition. Writing on the web is, ideally for the
reader, maintained, if that's appropriate. Even if you're not
maintaining the links after you've published something, you might want,
if you're writing over a long period of time, to at least assert that
the links you may have added sometime ago are still valid at
publication. Electronic formats at least offer this possibility, even if
that possibility is often unfulfilled.&lt;/p&gt;
&lt;p&gt;Writing often becomes less relevant with time — particularly in the
current climate of "content creation" (and it is difficult to see right
now how this might ever slow down). But some ideas do have a more
enduring relevance. Although, even if the ideas endure, the URLs linked
as part of that work may not. Often, an author may link to sources they
did not create and do not have any control over. If a resource you don't
control disappears, then, well, it disappears.&lt;/p&gt;
&lt;h2 id="validating-links"&gt;Validating links&lt;/h2&gt;
&lt;p&gt;So, let's assume what you've written is useful or relevant, at least, to
readers present and future. How can you validate that the links you have
in whatever documents you're dealing with are still functioning?&lt;/p&gt;
&lt;p&gt;You could hack together a shell script or similar that will do this and
give you a good idea of which links are broken. It's often less work to
choose existing software, should something suitable exist, for fairly
common tasks. The authors have then done the work for you, including
thinking about handling any awkward cases or behaviour.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/lycheeverse/lychee"&gt;lychee&lt;/a&gt; is one such program
designed to check URLs in collections of text-based source files. You
can also run it against a website, but I've found it most useful for
"local"&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt; files.&lt;/p&gt;
&lt;p&gt;A lychee link check runs &lt;em&gt;very&lt;/em&gt; quickly. Each run gives you a summary of
how many links were checked, how many were successful and reasons for
failures. As a guide, the link checking step in a GitHub Actions lychee
run takes about 10 seconds for a site with about 450 URLs.&lt;/p&gt;
&lt;h3 id="whats-nice-about-lychee"&gt;What's nice about lychee&lt;/h3&gt;
&lt;p&gt;lychee is particularly useful in that it can check various plain text
formats: whether HTML, Markdown, reStructuredText, or other text files.
You can also point to an existing website and check the links there.&lt;/p&gt;
&lt;p&gt;On top of that, lychee is cross-platform. Since I have always run it via
GitHub's hosted virtual machine runners, it's perhaps less important how
it runs.&lt;/p&gt;
&lt;p&gt;As a quick summary, it's nice that it worked well from the start,
without spending lots of times debugging. The results I initially got
from it were, on the the whole, useful.&lt;/p&gt;
&lt;h2 id="possible-applications"&gt;Possible applications&lt;/h2&gt;
&lt;p&gt;There are more uses than you might first think of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;web content (the obvious use)&lt;/li&gt;
&lt;li&gt;"formal" documentation sources&lt;/li&gt;
&lt;li&gt;collections of less formal READMEs that act as documentation within a
  coding project&lt;/li&gt;
&lt;li&gt;a research paper or thesis, to check the links before submission&lt;/li&gt;
&lt;li&gt;anywhere else you have a collection of text files (applied to
  collections of notes, or digital
  &lt;a href="https://en.wikipedia.org/wiki/Zettelkasten"&gt;Zettelkästen&lt;/a&gt; or similar)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And checking links has the auxiliary benefit of checking your own
content: if the links that relate to a particular point are defunct, it
may be that the underlying information or situation has changed. That's
particularly the case with computing where information can date rapidly,
due to software or hardware developments or changes in best
practice.&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id="some-usage-notes"&gt;Some usage notes&lt;/h2&gt;
&lt;h3 id="within-github"&gt;Within GitHub&lt;/h3&gt;
&lt;p&gt;It is possible to run lychee within a GitHub Actions runner. There is an
existing &lt;a href="https://github.com/lycheeverse/lychee-action"&gt;action&lt;/a&gt; or you
could write your own workflow to download and run the latest version.&lt;/p&gt;
&lt;p&gt;This way, you can run lychee automatically, either on a schedule or on a
pull request. This works relatively well, with the additional benefit
that the link checking isn't being done using your own internet
connection.&lt;/p&gt;
&lt;p&gt;Other tips for running in GitHub Actions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For checking GitHub links, you may want to use &lt;code&gt;GITHUB_TOKEN&lt;/code&gt; with
  lychee or the action which avoids rate limiting. You may want to
  restrict that token, to, for example, just &lt;em&gt;read&lt;/em&gt; the contents of the
  repository with the &lt;code&gt;permissions&lt;/code&gt; key.&lt;/li&gt;
&lt;li&gt;GitHub Actions runners get blocked by various sites, so you may have
  to exclude a few links. You can add a &lt;code&gt;.lycheeignore&lt;/code&gt; file which
  allows you to specify links via regular expressions.&lt;/li&gt;
&lt;li&gt;You cannot check email addresses within a GitHub-hosted runner, so you
  need to use the &lt;code&gt;--exclude-mail&lt;/code&gt; option.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="outside-of-github"&gt;Outside of GitHub&lt;/h3&gt;
&lt;p&gt;Restrictions outside of GitHub might be less onerous, but at the risk of
getting your IP address rate limited or even temporarily blocked. So I'd
be very wary of running something like lychee using a personal internet
connection.&lt;/p&gt;
&lt;p&gt;If you have access to cloud virtual machines, that might be another
option. However, the IP address ranges that such a virtual machine might
have could already be blocked by the sites (or their hosting providers)
that you're trying to check.&lt;/p&gt;
&lt;p&gt;There are two things you could do to be careful:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set a maximum number of concurrent connections.&lt;/li&gt;
&lt;li&gt;Run the &lt;code&gt;--dump&lt;/code&gt; option just to see which links would be checked; if
  there are any in there which are important for you to access for and
  might rate limit or block you, maybe consider adding them to the
  &lt;code&gt;.lycheeignore&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="wherever-youre-running"&gt;Wherever you're running&lt;/h3&gt;
&lt;p&gt;Basic authentication is supported for logging into sites, but links that
require some kind of two-factor authentication can't be checked. Whether
you want to go to the trouble of creating an account, particularly if
that account's credentials are solely for GitHub use, just for checking
a few links is another question.&lt;/p&gt;
&lt;h3 id="integrating-into-a-documents-build-process"&gt;Integrating into a document's build process&lt;/h3&gt;
&lt;h4 id="a-rough-strategy"&gt;A rough strategy&lt;/h4&gt;
&lt;p&gt;Initially, particularly for a collection of files that may have not been
written or reviewed recently, it's likely that there are several broken
links.&lt;/p&gt;
&lt;p&gt;This is the approach I've taken:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Run lychee.&lt;/li&gt;
&lt;li&gt;Review the error log.&lt;/li&gt;
&lt;li&gt;Check and classify the failures.&lt;/li&gt;
&lt;li&gt;Decide whether to fix up links, or ignore them by adding to a
   &lt;code&gt;.lycheeignore&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;Repeat the previous steps until you have no errors.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can see a real-world example of this &lt;a href="https://github.com/opensafely/documentation/issues/642"&gt;that I used at
work&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id="resolving-failures"&gt;Resolving failures&lt;/h4&gt;
&lt;p&gt;Failures tended to fall into one of these categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Genuinely broken links.&lt;/li&gt;
&lt;li&gt;Links to resources that are restricted to authorised users: you need
  to login first.&lt;/li&gt;
&lt;li&gt;Links that were inaccessible from within the GitHub Actions runner
  virtual machines.&lt;/li&gt;
&lt;li&gt;Internal Markdown or HTML template links that were not getting
  interpreted correctly, and, in some cases, could be corrected.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My approach has been to skim through the errors by hand and classify
them. You can also get JSON output if it's useful to have a directly
machine-readable format.&lt;/p&gt;
&lt;p&gt;From the errors and your investigation, you can create a &lt;code&gt;.lycheeignore&lt;/code&gt;
file: an exclusion list of links. That file is used if it is in the
working directory, or you can specify its path explicitly via lychee's
options. Adding a &lt;code&gt;.lycheeignore&lt;/code&gt; file at the top-level of your source
repository, if you are using a version control repository, works well.&lt;/p&gt;
&lt;p&gt;You can specify exclusions by regular expressions: excluding subdomains
works quite well when there are multiple links to that subdomain. You
can just include the direct URL if there's just one specific URL for a
specific domain you want to exclude. It's worth generalising the
exclusion once you get more variations of a single URL or domain.&lt;/p&gt;
&lt;p&gt;For fixing up broken links, then either you need to find where the
relevant URL has moved to, if it is still available, or review whether
the &lt;a href="https://web.archive.org"&gt;Internet Archive&lt;/a&gt; has a copy saved. If
it's for a blog post, you might want to pick a version that's close in
date to when you added the link to that post: that version is possibly
what you'll have been reading. Alternatively, you could review the most
recent available version and use that version if suitable.&lt;/p&gt;
&lt;p&gt;For the couple of projects I've tried lychee with, it's able to check
something like 80-90% of URLs. The checks have been useful and have
flagged URLs and surrounding text that require updating. This will vary
depending on where the URLs you are checking point to though.&lt;/p&gt;
&lt;h3 id="miscellaneous-tips"&gt;Miscellaneous tips&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If you are particularly finicky, it is possible to flag redirects by
  setting the number of maximum redirects to 0. And it is possible to
  check for non-HTTPS web URLs: these days most URLs should be available
  via HTTPS.&lt;/li&gt;
&lt;li&gt;You can set another User-Agent. I've not tried this to see if it
  improves the accessibility of some URLs.&lt;/li&gt;
&lt;li&gt;Excluding directories is, at time of writing, clunky; see the
  &lt;a href="https://github.com/lycheeverse/lychee/issues/470"&gt;associated GitHub
  issue&lt;/a&gt;. This is the
  only finicky usability hurdle I've encountered.&lt;/li&gt;
&lt;li&gt;If your documents are not in a supported format, lychee is still
  potentially useful. You would need to export your document to a plain
  text format, either in whatever authoring tool you are using, or with
  something like &lt;a href="https://pandoc.org"&gt;pandoc&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;There are lots of other options that you can use with lychee: take a
  look at the documentation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="persistence-of-web-content"&gt;Persistence of web content&lt;/h2&gt;
&lt;p&gt;So, you can probably tell: I think lychee is a really useful tool.&lt;/p&gt;
&lt;p&gt;However, its usefulness comes with a caveat: &lt;strong&gt;all lychee can do is tell
you whether a link is accessible or not&lt;/strong&gt;. But, wait, you might argue:
that's the whole point of this post that I'm reading — we &lt;em&gt;want&lt;/em&gt; to
check links, right?&lt;/p&gt;
&lt;p&gt;In a way, yes.&lt;/p&gt;
&lt;p&gt;All a valid link tells you is that the relevant resource provider has
some resource available and accessible at that URL.&lt;/p&gt;
&lt;p&gt;It &lt;strong&gt;doesn't&lt;/strong&gt; assure you that whatever you've linked to is in anything
like the state it was when you read it. There are no guarantees that
typical web URLs point to static or immutable content. They work more
like pointers: it's up to the relevant server hosting the URL's domain
and the people who put content on that server that decide what the
content is.&lt;/p&gt;
&lt;p&gt;In many cases, this could be fine. In others, maybe less so:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The original author may have updated their content in a way that might
  change the relevance to whatever argument or citation you intended to
  make.&lt;/li&gt;
&lt;li&gt;Another organisation could have taken over (perhaps legitimately,
  perhaps not) the site and decided to post a contrary view, or
  something entirely different at the same URL.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Making HTTP requests and checking for a non-error response codes only
tells you that a resource is available at that URL, whether directly or
with redirection somewhere else. It doesn't guarantee that a resource is
actually as you read it, when you read it.&lt;/p&gt;
&lt;h3 id="preservation"&gt;Preservation&lt;/h3&gt;
&lt;p&gt;You may now be thinking: well, I could just take a copy and link to
that, providing my own cache of the resource as it was when I reviewed
it. That would work, but hosting that copy is probably a bad idea:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There are potential copyright issues.&lt;/li&gt;
&lt;li&gt;If you're intending to host this copy on the web, then, if it is
  public and discoverable, it's possible that search engine providers
  think you're up to some kind of nefarious search engine optimisation
  shenanigans.&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Much simpler is linking to the &lt;a href="https://web.archive.org"&gt;Internet
Archive&lt;/a&gt;: either finding a "good" copy there
already, or using their page save feature to archive a copy of the page
there and then.&lt;/p&gt;
&lt;p&gt;Wait, so why wouldn't we just always link to the Internet Archive?&lt;/p&gt;
&lt;p&gt;In some limited cases, this might be useful, where you want readers to
have the information as you accessed it at the time. That is
particularly useful if you are specifically citing a work and the
version available at a given time. In many other cases, it is still
useful to link to the "live" resource because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You may be pointing to an interactive service, and the Internet
  Archive's more static version may not function correctly, without
  access to the original host's backend servers.&lt;/li&gt;
&lt;li&gt;You may want your readers to always access the latest published
  version of the information that you link.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we link to the original host instead of a third-party preservation
service, this does pose the future risk of the resource being
unavailable in future. But tools like lychee can definitely help with
maintaining working URLs.&lt;/p&gt;
&lt;p&gt;And, finally, if you're now asking: "what guarantees are there on
availability and integrity of the content the Internet Archive hosts".
Or maybe more succinctly: "who archives the archivers?" Let's say that
those are also good questions, but there are already enough words here
not to worry about this here and now.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Unless you've tried to subvert that by printing this out. You
  rascal.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;The quote marks are because all my running of lychee has been via
  GitHub Actions: a "local" checkout of my source files on a remote
  virtual machine.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;Indeed, Stack Overflow are finding this a problem. It turns out
  that sifting through years of accumulated answers, some now
  deprecated, is a &lt;a href="https://meta.stackoverflow.com/questions/405302/introducing-outdated-answers-project"&gt;big spring cleaning
  task&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;That said, there is less evidence from Google's search results
  that this rule is actually &lt;em&gt;enforced&lt;/em&gt;. Sites that are obviously
  cloning contents from other sites do sometimes rank quite highly.&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="2022"></category><category term="blog"></category><category term="documentation"></category><category term="documentation as code"></category><category term="link"></category><category term="lychee"></category><category term="URL"></category><category term="research software engineering"></category><category term="writing"></category></entry><entry><title>PyCon 2021: Secure software supply chains</title><link href="https://www.stevenmaude.co.uk/posts/pycon-2021-secure-software-supply-chains" rel="alternate"></link><published>2021-10-15T17:27:00+01:00</published><updated>2021-10-15T17:27:00+01:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2021-10-15:/posts/pycon-2021-secure-software-supply-chains</id><summary type="html">&lt;p&gt;A summary of a talk by Dustin Ingram at PyCon 2021.&lt;/p&gt;</summary><content type="html">&lt;h2 id="modern-python-less-modern-me"&gt;Modern Python, less modern me&lt;/h2&gt;
&lt;p&gt;I've been working for the past few months at The DataLab — now Bennett
Institute for Applied Data Science. There, Python is the main language
for development and collectively the developers have a lot of Python
experience.&lt;/p&gt;
&lt;p&gt;Because of that, I've seen a lot more modern Python than I was
accustomed to seeing or writing. What I've found is what I knew about
Python is a little outdated. Certainly there have been a lot of new
Python features introduced that I didn't know about or only vaguely had
heard of, e.g.:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dataclasses &lt;/li&gt;
&lt;li&gt;assignment expressions, i.e. &lt;code&gt;:=&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;breakpoint()&lt;/code&gt; instead of having to import and use the &lt;code&gt;pdb&lt;/code&gt; package
  directly&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It seemed wise to me then to watch some recent conference talks. I may
write up notes on them. All that said, let's look at the first one.&lt;/p&gt;
&lt;h2 id="secure-software-supply-chains-for-python"&gt;Secure Software Supply Chains for Python&lt;/h2&gt;
&lt;p&gt;This is a summary of &lt;a href="https://www.youtube.com/watch?v=VWWgkF-0cDQ"&gt;this
talk&lt;/a&gt; by Dustin Ingram, a
PyPI maintainer.&lt;/p&gt;
&lt;p&gt;The talk describes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What software supply chain attacks are.&lt;/li&gt;
&lt;li&gt;The current best Python practice for developes.&lt;/li&gt;
&lt;li&gt;What improvements could be made to &lt;code&gt;pip&lt;/code&gt; and PyPI in future.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="supply-chain-attacks"&gt;Supply chain attacks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;They are a thing.&lt;ul&gt;
&lt;li&gt;Involve a compromise of your dependencies, where they are
  distributed and everything used to build them.&lt;/li&gt;
&lt;li&gt;This applies recursively to your dependencies' dependencies and so
  on.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="types-of-supply-chain-attack"&gt;Types of supply chain attack&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;MITM attack: intercepting a package download and replacing it with
  something malicious.&lt;/li&gt;
&lt;li&gt;Typosquatting: uploading malicious packages with names similar to
  well-known packages.&lt;/li&gt;
&lt;li&gt;Dependency confusion: where internal, non-public packages are used,
  but &lt;code&gt;pip&lt;/code&gt; is misconfigured to check PyPI first and someone registers a
  malicious public package with the same name as the internal package.&lt;/li&gt;
&lt;li&gt;"Research": people deliberately introducing vulnerabilities into code.&lt;/li&gt;
&lt;li&gt;SolarWinds was mentioned as an example: compromise of build system.&lt;/li&gt;
&lt;li&gt;Compromised maintainers.&lt;/li&gt;
&lt;li&gt;Compromised source control.&lt;/li&gt;
&lt;li&gt;Leaked passwords/API tokens.&lt;/li&gt;
&lt;li&gt;Social engineering.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="python-best-practices"&gt;Python best practices&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;For Python, best current practices are:&lt;ul&gt;
&lt;li&gt;Use pinned requirements and with hashes, e.g. via &lt;code&gt;pipenv lock&lt;/code&gt;,
  or &lt;code&gt;pip-compile --generate-hashes&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Use some notification service that monitors dependencies in your
  source, e.g. Dependabot (this is convenient, but is an extra
  component in the supply chain: you have to trust that Dependabot
  isn't creating malicious pull requests).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;There are other possible future improvements to PyPI and &lt;code&gt;pip&lt;/code&gt;:&lt;ul&gt;
&lt;li&gt;Removal of &lt;code&gt;setup.py&lt;/code&gt; support to stop arbitrary code being run at
  install time. That might save you if you realise you've installed
  a compromised package, before importing and using the package.&lt;/li&gt;
&lt;li&gt;Signed repository metadata (&lt;a href="https://www.python.org/dev/peps/pep-0458/"&gt;PEP 458&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Having namespaces on PyPI.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><category term="2021"></category><category term="PyCon"></category><category term="Python"></category></entry><entry><title>A review of "UNIX: A History and a Memoir"</title><link href="https://www.stevenmaude.co.uk/posts/a-review-of-unix-a-history-and-a-memoir" rel="alternate"></link><published>2021-05-08T00:12:00+01:00</published><updated>2021-05-08T12:16:00+01:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2021-05-08:/posts/a-review-of-unix-a-history-and-a-memoir</id><summary type="html">&lt;p&gt;A quick recommendation of an easy-to-read and brisk summary of the development of UNIX.&lt;/p&gt;</summary><content type="html">&lt;p&gt;"UNIX: A History and a Memoir" is from the perspective of Brian
Kernighan, who was around at the inception of UNIX, and is well-known in
computing himself as one of the three authors of the AWK language and
the author of a number of other influential books (e.g. "The C
Programming Language" by Kernighan and Ritchie). The title covers most
of what the book deals with: the formative years of UNIX, with
explanation of the key software that was developed as part of it.&lt;/p&gt;
&lt;p&gt;It explains where UNIX was developed and who did that work. Initially,
UNIX was one of Ken Thompson's side projects, quickly capturing wider
interest and sparking collaboration within Bell Labs. This was all amid
a milieu of Bell Labs having considerable operating system development
experience as a collective, yet having no operating system to work on.
(Bell Labs had been working on the Multics project, but eventually
withdrew its support.) Eventually, management managed to gather funding
for UNIX, initially with a view to improving how patent applications
within Bell Labs were prepared.&lt;/p&gt;
&lt;p&gt;From there, UNIX developed sufficiently that it found wider use within
Bell Labs, within AT&amp;amp;T — Bell Labs' then parent company — and within
many universities. Eventually UNIX was sold commercially. Later, while
various commercial UNIX vendors expended much efforts in commercial
wrangling of various parties, the appearance of the free Linux kernel in
the early 1990s paved the way for Linux distributions to render the
commercial squabbles largely obsolete.&lt;/p&gt;
&lt;p&gt;Kernighan's rundown of the features that made UNIX distinct from many of
the competitors at the time explains why UNIX was a key development that
transformed computing at the time, offering:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a hierarchical file system;&lt;/li&gt;
&lt;li&gt;accessible system calls;&lt;/li&gt;
&lt;li&gt;abstraction of other concepts, such as hardware devices, that they
  could be worked with much as regular files;&lt;/li&gt;
&lt;li&gt;a command-line shell that could be used composably, along with a suite
  of programs as useful tools, pipes and scripting to connect those
  programs together to effectively create new commands or programs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Half a century on and these features are still evident in Linux and
other descendants that are still being developed today.&lt;/p&gt;
&lt;p&gt;Kernighan closes the book by describing factors that made Bell Labs such
a successful research institution. That in itself is an interesting
story that entwines with the development of UNIX. My distillation is
that Bell Labs had an extended period where the organisation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;had interesting and challenging problems to solve;&lt;/li&gt;
&lt;li&gt;hired very talented staff to solve those problems;&lt;/li&gt;
&lt;li&gt;had sufficient resources that the staff did not need to worry about
  funding, while management could take a longer view on projects without
  demanding immediate results;&lt;/li&gt;
&lt;li&gt;had a technically competent management;&lt;/li&gt;
&lt;li&gt;offered a collaborative and fun environment for this research.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All easier written than done, of course. If it were so simple, that
research model would be simply replicated everywhere given the
resources. Nonetheless, this goes some way to summarise why Bell Labs
were so extraordinarily influential and tremendously prolific in 20th
century technology developments.&lt;/p&gt;
&lt;p&gt;Finally, the book also puts the development of UNIX into context in
modern-day computing. Many computing devices today run operating systems
that have some connection back to UNIX. Even Microsoft has adopted
several of the ideas made popular by UNIX, and has, at times, veered
closer to UNIX and its descendants, offering Windows Services for UNIX
in the past, Windows Subsystem for Linux in the present and, long ago,
even distributing XENIX, Microsoft's very own UNIX distribution! While
UNIX is over 50 years old, it continues to influence today's computing:
this well-written book certainly helps to understand why that is so.&lt;/p&gt;</content><category term="2021"></category><category term="book"></category><category term="computing"></category><category term="history"></category><category term="Linux"></category><category term="review"></category><category term="UNIX"></category></entry><entry><title>Tracking down tracks</title><link href="https://www.stevenmaude.co.uk/posts/tracking-down-tracks" rel="alternate"></link><published>2021-04-24T22:45:00+01:00</published><updated>2021-04-24T22:45:00+01:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2021-04-24:/posts/tracking-down-tracks</id><summary type="html">&lt;p&gt;Strategies for finding details on elusive pieces of music.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Having recently gone through an extensive process — well, thirty minutes
or so of searching — to find a piece of music, I wanted to document the
approaches I know of for this process.&lt;/p&gt;
&lt;p&gt;Here, for "music", I'm primarily thinking about relatively modern
Western dance music from the 1970s to the present day — disco to
dubstep, and beyond. Some ideas detailed here may well apply to other
genres and time periods.&lt;/p&gt;
&lt;h2 id="take-a-recording"&gt;Take a recording&lt;/h2&gt;
&lt;p&gt;What if you're listening to something right now and want to track it
down? Record it. There's a lot to be said about the ubiquity of phones.
Here though, having a portable recording device in your pocket is really
useful. Someone you want to ask or some tool you want to use will have a
much easier time with a real recording, even if imperfect, over merely a
description or your best guess at humming or singing the music.&lt;/p&gt;
&lt;p&gt;There are several music recognition applications that are very effective
and well-known these days. These typically work by submitting an audio
fingerprint to the application owner's servers and searching for that in
their databases. I don't personally use these applications, though I
have tried them occasionally in the past.&lt;/p&gt;
&lt;p&gt;It is possible to use these applications live while the music is
playing. But you still might favour taking a recording first so that you
can easily share that elsewhere. Audio recognition applications may not
cover every piece of music ever recorded, but they are potentially a
useful first look. As these applications often run on mobile devices,
there is a privacy-related caveat&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;, however.&lt;/p&gt;
&lt;p&gt;With an audio clip of interest — whether by recording it yourself, or
snipping it from an existing piece of digital audio — an alternative is
to upload the audio to a site that detects content, e.g. SoundCloud,
Mixcloud, YouTube etc. Primarily the reason is for these services to
detect copyrighted content and either block your submission, or at least
monetise it for the copyright owner. But you can repurpose this to
identify the audio for you.&lt;/p&gt;
&lt;p&gt;This is also useful if you want to identify lots of tracks from one
source, e.g. a DJ mix, in one go. Often, I've listened to things on
YouTube and spotted the video description details several of the tracks
in there.&lt;/p&gt;
&lt;p&gt;And what to do if recording isn't possible, the recording fails or is
not clear enough to be useful? If there are lyrics or a vocal sample,
then remembering the most frequent lyric and/or distinctive lyrics is
helpful. A frequently repeated lyric, or a modification of it, may well
be the music's title. Lyric fragments are easily searched for.&lt;/p&gt;
&lt;h2 id="narrowing-down"&gt;Narrowing down&lt;/h2&gt;
&lt;p&gt;Searching for the text used in lyrics or repeated vocal samples can be a
good start. Because vocals are often sampled from elsewhere, you may end
up first locating the original sample source. If you do, that's a lead:
you can next try and search for which tracks sampled that vocal.
Especially in early 90s tracks, certain acapellas that were used many,
many times.&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;You can also search for the name of the genre, along with the lyric
snippet. This might also help get you to some place on the web. That
might be where the release is indexed in some kind of database, e.g.
Discogs. It might occasionally be some place where someone else is
asking the same question as you, possibly with a helpful reply.&lt;/p&gt;
&lt;p&gt;Try restricting a search to some of the bigger music-related databases
online. You can try using the &lt;code&gt;site:&lt;/code&gt; operator on search engines that
support it to narrow your search. Looking for a combination of the
artist and name of original track, optionally with a genre on Discogs,
&lt;code&gt;site:discogs.com&lt;/code&gt;, might help.&lt;/p&gt;
&lt;p&gt;If it's a mix with a dated year, you can probably narrow down your
search to a year or two; the release may well be from that same year or
previous years. It does roughly narrow it down, but not precisely. If
the recording is from towards the end of a year, the release might have
been the next year (or even later) if it has been shared with DJs ahead
of release. If there are commercial issues, e.g. trouble with sample
clearance or labels, it might never have been officially released, or
may have been released considerably later.&lt;/p&gt;
&lt;p&gt;If it's a genre you know well and particularly for Western electronic
dance music, especially historically, you can probably have some kind of
guess as to when a piece of music was produced to the nearest couple of
years. Even for today's dance music, where there might not be the same
huge difference in recording techniques as there was from the 1980s to
2000s, there may certainly be trends, common production styles or
popular sounds or samples. That said, there's also a fashion for making
things sound like they used to — producers can use the same techniques
and equipment that were popular during a certain period to replicate it
— so don't always assume your guess is correct.&lt;/p&gt;
&lt;p&gt;Another approach that might work if others don't and the track was in a
DJ set is finding more sets by the same DJ from around the same time
period. Narrow down by looking for sets with tracklistings and then skim
through to see if the same track appears. This requires some luck, but
might just work.&lt;/p&gt;
&lt;h2 id="getting-help-from-others"&gt;Getting help from others&lt;/h2&gt;
&lt;p&gt;If you hear the music at an event you're actually attending and a DJ is
playing, or played the track, well, you can try asking them either at
the event, or after the fact online. This is more likely to be
successful at small events. You can always try this if it's a bigger
show or the DJ in question is a bigger name, though that may be less
successful.&lt;/p&gt;
&lt;p&gt;If it's a recorded DJ mix, there may well be a tracklisting somewhere.
That goes especially if it's a commercial mix, or if it was a radio
broadcast (where stations often list show details on their websites).&lt;/p&gt;
&lt;p&gt;If the mix is on SoundCloud or YouTube, you can look at the description
or the comments. Sometimes, particularly on SoundCloud, you might get
the DJ themselves, the artist or someone else who follows that DJ or
genre naming some or all of the tracks.&lt;/p&gt;
&lt;p&gt;If all that fails, you could always try asking somewhere online. If it's
a mix that's already posted online, you could ask in the comments of
that mix. If it's audio that you've recorded elsewhere, you can upload
it somewhere, or describe it as best you can. Find a suitable place to
then post that question. That could be somewhere more general, like the
Discogs forums, or more specific where certain music genres are the
focus.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;The caveat is that there are possible privacy issues with using
  these types of applications. These applications may request
  permissions to record audio, as well as locating you via GPS or to a
  lesser extent, IP address. Incidentally, Shazam were bought by Apple,
  and Apple seem to place some priority on user privacy. Having not used
  Shazam much, if at all, I'm not necessarily advocating it though.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;A good question, that I can't answer right now, is &lt;em&gt;why&lt;/em&gt; certain
  vocals were reused so much. Was it because of the availability of the
  original acapella? Was it because the vocal has a particular sound?
  Was it a deliberate reference to the existing popular reuse?&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="2021"></category><category term="DJ"></category><category term="music"></category></entry><entry><title>Things I have learned from rebuilding a PC in 2021</title><link href="https://www.stevenmaude.co.uk/posts/things-i-have-learned-from-rebuilding-a-pc-in-2021" rel="alternate"></link><published>2021-02-26T14:02:00+00:00</published><updated>2021-02-26T14:02:00+00:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2021-02-26:/posts/things-i-have-learned-from-rebuilding-a-pc-in-2021</id><summary type="html">&lt;p&gt;What are you buying? What are you selling?&lt;/p&gt;</summary><content type="html">&lt;p&gt;Despite working with computers (supposedly) professionally, I don't
often build PCs or upgrade PC hardware. A few years ago, I learned a few
lessons from &lt;a href="https://www.stevenmaude.co.uk/posts/things-ive-learned-from-building-and"&gt;building a PC&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Over the 2020 Christmas holidays, I was upgrading someone's PC for them,
so here are my lessons I've thought about in 2021.&lt;/p&gt;
&lt;h2 id="buying-pc-parts-is-not-easy"&gt;Buying PC parts is &lt;em&gt;not&lt;/em&gt; easy&lt;/h2&gt;
&lt;p&gt;In the UK at least, the latest processors (CPUs) and graphics cards
(GPUs) were out of stock at the time of buying. That is probably due to
some or all of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;COVID-19 related supply chain issues;&lt;/li&gt;
&lt;li&gt;releases of hardware in the run up to the holiday period;&lt;/li&gt;
&lt;li&gt;the current trend for people to buy coveted, in-demand trinkets
  (fashion, new generation video game consoles, hand sanitiser) and
  resell at higher than retail price;&lt;/li&gt;
&lt;li&gt;demand from people stuck at home and spending money on PC hardware
  instead of other things.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Adding to all that, the 2021 changes in UK trade due to Brexit may not
help either. However, the fundamental issue of shortages applies
globally from what I've read.&lt;/p&gt;
&lt;p&gt;Pent-up demand then drove up prices of older kit. By chance, I managed
to spot AMD's new Ryzen 5 5600x CPUs available just before Christmas
from a retailer at slightly higher than the billed retail price. Somehow
I also managed to order while holding my nose at the inflated cost. I
wasn't actually intending to buy the latest CPU, but the previous
generation Ryzen 5 3600x was being priced at around 75-80% of the cost
of the newer kit anyway.&lt;/p&gt;
&lt;p&gt;This might all resolve itself in time. I could do with a new desktop
build myself, but not really inclined to do so right now. Reading
around, it seems like stock shortages, particularly for GPUs, will
continuing well into 2021.&lt;/p&gt;
&lt;h2 id="buying-from-a-retailer-with-good-returns-policies-can-save-time"&gt;Buying from a retailer with good returns policies can save time&lt;/h2&gt;
&lt;p&gt;Here's a long and dull story; feel free to skip to the lessons below.
As part of the same build, and after a lot of research, I ordered a
mainboard that was on offer, as researching it showed it to be a good
buy. As lots of mainboards are, it seemed to be one with lots of RGB
LEDs — nice if you want that, but unnecessary to me — and I figured you
could disable the LEDs easily.&lt;/p&gt;
&lt;p&gt;Shortly after ordering, I discovered that you couldn't simply toggle the
LEDs off in the BIOS. Instead, you had to have the mainboard's
manufacturer's clunky software — nice if you want that, but unnecessary
to me — running constantly on Windows to control the LEDs.&lt;/p&gt;
&lt;p&gt;I tried to cancel the board order. The order hadn't yet moved to the
stage of being prepared for shipping and was temporarily out of stock
anyway. So I sent a message via the website and hoped they would cancel
on the next working day. This was almost out of office hours, and I
figured that everything would be OK.&lt;/p&gt;
&lt;p&gt;About an hour later, I got another email saying the order was
dispatched. From there, things became more of a mess. The next morning,
the courier shipping the order sent me a message with delivery options
including delaying the delivery. I delayed it, the courier still arrived
with the parcel and I explained that I'd deferred delivery.&lt;/p&gt;
&lt;p&gt;After a phone call to the company I ordered from, confirming I could
refuse delivery and they would create an returns number, I waited a
week, and heard nothing at all. There was no repeat delivery and I
assumed the parcel was in limbo somewhere.&lt;/p&gt;
&lt;p&gt;In the end, it took over a week for the company to get the parcel back
from the courier, it then took a further two written requests to
customer support to finally receive my money back.&lt;/p&gt;
&lt;p&gt;I told you it was a long and dull story. No refunds.&lt;/p&gt;
&lt;h3 id="a-long-and-dull-story-with-two-lessons-learned"&gt;A long and dull story with two lessons learned&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ordering from a company that has an automated online system for
  cancelling orders is useful for sudden onset of buyer's remorse.&lt;/li&gt;
&lt;li&gt;Ordering from a company that has a good and simple returns process is
  useful if you find the hardware isn't right after you've received it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is one obvious market-leading online retailer that has these
attributes, but may not be everyone's first choice for various reasons.
Nonetheless, on customer service, these attributes are fantastic from a
buyer's perspective.&lt;/p&gt;
&lt;p&gt;I don't frequently make regrettable purchases. But you can do all the
reading of specifications, manuals, reviews and opinions that you like,
and still find two PC components just will not get along for whatever
reason.&lt;/p&gt;
&lt;p&gt;Having no-fuss returns can save you a lot of time and frustration
chasing up customer support. In the UK, there is &lt;a href="https://www.legislation.gov.uk/ukpga/2015/15/contents"&gt;substantial current
legislation regarding consumer
rights&lt;/a&gt;. However,
it's far simpler as a customer if the vendor already provides better
than the minimum customer service.&lt;/p&gt;
&lt;h2 id="selling-pc-parts-is-easy"&gt;Selling PC parts &lt;em&gt;is&lt;/em&gt; easy…&lt;/h2&gt;
&lt;p&gt;After the upgrade, we advertised the old removed parts online. They all
sold within a week, and the proceeds could be spent on a new graphics
card, if you could buy one (see above). I was surprised at both how
quickly these old components sold and for what we sold them for. Some
parts sold for not much less than they cost at retail. It's possible
that people are looking for budget builds, or upgrading/repairing
existing builds.&lt;/p&gt;
&lt;h3 id="but-make-sure-you-upgrade-any-firmware-before-selling"&gt;…but make sure you upgrade any firmware before selling&lt;/h3&gt;
&lt;p&gt;After the mainboard sold, the buyer asked about what CPU was used with
it; it wasn't working for them and they were trying to diagnose it. When
they booted up the PC, nothing happened.&lt;/p&gt;
&lt;p&gt;Between the details the buyer gave and reading around the BIOS release
notes for the mainboard, we concluded that it was probably a combination
of the mainboard BIOS never being updated, and the buyer using a newer
CPU than had previously been installed.&lt;/p&gt;
&lt;p&gt;It was lucky that there was a route to flashing the BIOS without a CPU
via one of the USB ports. Decent mainboards often feature this recovery
option. That meant the buyer could solve this problem without borrowing
or buying another CPU to upgrade the BIOS, or, worse for us, returning
the item.&lt;/p&gt;
&lt;p&gt;The wise thing to do is to upgrade the firmware, if there is any, before
removing components.&lt;/p&gt;
&lt;h2 id="what-tedious-cpu-cooler-installations-should-tell-hardware-manufacturers-about-marketing"&gt;What tedious CPU cooler installations should tell hardware manufacturers about marketing&lt;/h2&gt;
&lt;p&gt;Two very disparate ideas in the heading there; let's see if there's
anything like a cohesive argument here.&lt;/p&gt;
&lt;p&gt;Last time I wrote about &lt;a href="https://www.stevenmaude.co.uk/posts/things-ive-learned-from-building-and"&gt;building a
PC&lt;/a&gt;, I had
lots of fun installing Intel's push pins. This time I had fun with
fitting a cooler to an AMD setup. It didn't use screws. Instead the
cooler used long metal tweezer-like clips to fit over the tabs on the
AM4 socket on the mainboard.&lt;/p&gt;
&lt;p&gt;How this all was assembled to secure the cooler was not obvious at all.
The lack of clear instructions did not help one bit. The text basically
said "build the thing and look at the diagram". The diagram wasn't
clear.&lt;/p&gt;
&lt;p&gt;Nor were there many decent YouTube tutorials on this. Eventually I
managed to piece together what to do from looking collectively at
several installation videos in several different languages. Even then,
it was a delicate task to keep the assembly together, while placing the
cooler contact directly on the CPU package and not smudging thermal
paste everywhere.&lt;/p&gt;
&lt;p&gt;As an esteemed non-influencer, hardware manufacturers are doing whatever
the opposite is of queuing up to ask me what I think. But if there ever
did suddenly appear an itinerant queue of manufacturers on my doorstep,
what I'd advise them is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Instead of relying on buyers of the hardware to provide tutorials,
  manufacturers should create or commission their own videos.&lt;/li&gt;
&lt;li&gt;Make sure these videos have appropriate metadata (title and
  description) to make them easy to find by those who need them.&lt;/li&gt;
&lt;li&gt;Provide videos in multiple languages, whether by audio, subtitles or
  both.&lt;/li&gt;
&lt;li&gt;Show less obvious steps from multiple angles.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's probably justifiable to spend a relatively small portion of a
marketing and/or support budget to ensure that there is a decent
installation video available. This is marketing and brand awareness:
you're demonstrating, hopefully, that your kit is easy to use, and,
importantly, providing support for users.&lt;/p&gt;
&lt;p&gt;I think it's a wider lesson for anyone selling anything — whether
hardware or software — that might require some tricky user installation.
Whether a prospective buyer seeing how to install something and deciding
to buy based on that, or an actual buyer not complaining online or
requesting a refund, there's a benefit for the vendor too.&lt;/p&gt;</content><category term="2021"></category><category term="PC"></category><category term="build"></category></entry><entry><title>Copying large iPhone videos to a Windows PC</title><link href="https://www.stevenmaude.co.uk/posts/copying-large-iphone-videos-to-a-windows-pc" rel="alternate"></link><published>2021-01-25T20:50:00+00:00</published><updated>2021-01-25T20:50:00+00:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2021-01-25:/posts/copying-large-iphone-videos-to-a-windows-pc</id><summary type="html">&lt;p&gt;How to copy iPhone videos that don't appear in Windows File Explorer&lt;/p&gt;</summary><content type="html">&lt;h2 id="a-simple-task-made-complicated"&gt;A simple task made complicated&lt;/h2&gt;
&lt;p&gt;This isn't a particularly interesting post. That is, unless you reading
this now, like me at the time of writing this, have spent the best part
of an hour trying to solve the same issue. Like a few other posts I've
made in the past, the purpose is really to make this easier to search
for, if others encounter the same problem.&lt;/p&gt;
&lt;p&gt;Someone had recorded a video on an iPhone that they wanted to transfer
to a Windows PC. Naturally, they connected the phone via a USB cable to
the computer, navigated through the existing &lt;code&gt;DCIM&lt;/code&gt; directories to copy
the files across and found, well, nothing. So they asked me about it.&lt;/p&gt;
&lt;p&gt;What was going on? They used the same process before and it worked fine.
And the videos were definitely still on the phone: you could play them
there. As these videos had large file sizes, I suspected there was some
limit being encountered.&lt;/p&gt;
&lt;h2 id="no-easy-answers"&gt;No easy answers&lt;/h2&gt;
&lt;p&gt;Many of the workarounds posted online seem to fit one of the following
categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Moving the video via iCloud, or some other uploading route. (Too slow
  and too tedious.)&lt;/li&gt;
&lt;li&gt;Using some other app to get the video to a PC. (May involve spending
  money and requires auditing the app to ensure it and the developers
  are reputable.)&lt;/li&gt;
&lt;li&gt;Re-encoding the video on the phone to a smaller size somehow, possibly
  via iMovie? (Didn't try this and may have been slow. This would have
  been the next thing I suggested if the solution below had not worked.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Apple documentation itself suggests making sure iTunes is installed,
using the Windows Photos app and then importing from there. This didn't
work.&lt;/p&gt;
&lt;h3 id="the-fix"&gt;The fix&lt;/h3&gt;
&lt;p&gt;I found someone posted a fix on a forum. On the iPhone's Settings,
select Photos, and then under "Transfer to Mac or PC" setting for the
Photos app, change "Automatic" to "Keep Originals". That was it. Much
simpler than any of the other suggestions.&lt;/p&gt;
&lt;p&gt;The import actually worked through the Photos app then. In fact, you did
not need Photos at all: checking the &lt;code&gt;DCIM&lt;/code&gt; directory listed the file.&lt;/p&gt;
&lt;p&gt;What "Keep Originals" does is take a direct copy of the photos and
videos, instead of doing some unspecified magic and converting them on
copy.&lt;/p&gt;
&lt;p&gt;(Though not tested, iPadOS has the same setting and presumably behaves
in the same way.)&lt;/p&gt;
&lt;p&gt;As someone unfamiliar with iOS, I'm not entirely sure how you would
connect the setting to the behaviour. But the main thing is that it
resolved a very frustrating and very badly documented issue very, very
quickly.&lt;/p&gt;</content><category term="2021"></category><category term="iOS"></category><category term="iPad"></category><category term="iPadOS"></category><category term="iPhone"></category><category term="Windows"></category></entry><entry><title>Garmin Forerunner 35: a competent budget running watch</title><link href="https://www.stevenmaude.co.uk/posts/garmin-forerunner-35-a-competent-budget-running-watch" rel="alternate"></link><published>2020-11-13T22:35:00+00:00</published><updated>2020-11-13T22:35:00+00:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2020-11-13:/posts/garmin-forerunner-35-a-competent-budget-running-watch</id><summary type="html">&lt;p&gt;A review of the Garmin Forerunner 35 after using for several months,
comparing with the Forerunner 15.&lt;/p&gt;</summary><content type="html">&lt;h2 id="replacing-a-garmin-forerunner-15-watch"&gt;Replacing a Garmin Forerunner 15 watch&lt;/h2&gt;
&lt;p&gt;Unsurprisingly, I've been doing a lot more exercise outdoors this year
than last, including a lot more running. So I've had a lot more time to
try out the Garmin Forerunner 35 GPS watch I've had since the end of
2019.&lt;/p&gt;
&lt;p&gt;I have owned a &lt;a href="https://www.stevenmaude.co.uk/posts/a-year-of-garmin-a-forerunner-15-review"&gt;Garmin Forerunner
15&lt;/a&gt; watch for a few years and,
especially considering what it cost, it served me well. The main issue
with it was that the battery life seemed to have deteriorated over its
lifetime. Changing the battery isn't too complex a procedure — there are
YouTube videos that show you how — but since the battery life was never
that great from new, it seemed worthwhile looking into getting a
different watch. And late last year, I saw an offer on a Garmin
Forerunner 35. The Forerunner 35, like the Forerunner 15, is again an
entry-level GPS watch, but it's a considerable upgrade from the
Forerunner 15.&lt;/p&gt;
&lt;h2 id="comparing-the-forerunner-35-to-the-forerunner-15"&gt;Comparing the Forerunner 35 to the Forerunner 15&lt;/h2&gt;
&lt;p&gt;Though the Forerunner 35 is comparably priced to what the Forerunner 15
cost when I bought it, there are a number of improvements and extra
features of the Forerunner 35 over the Forerunner 15.&lt;/p&gt;
&lt;p&gt;The Forerunner 35 is a less chunky, and more subdued design than the
Forerunner 15 — looking around, there's a Forerunner 25 that looks like
an odd hybrid of the 15 and 35 designs — and has walking and outdoor
cycling modes. The screen on the 35 is also higher resolution. There's a
built-in wrist heart rate monitor. I'm not entirely sure the heart rate
measurement is always that accurate, but it removes the need for an
external sensor, if a rough idea of heart rate is what you want. The
backlight is also an improvement over the Forerunner 15. There's also
the option to pair a phone via Bluetooth, though that's not something
I've bothered to use.&lt;/p&gt;
&lt;p&gt;On using the 35, the battery life does seem much improved over the 15. I
never wore the Forerunner 15 daily, only for runs. By contrast, I'm
wearing the Forerunner 35 I've used daily: it does need a charge every
week or so, but that doesn't usually take long. Even if low on power,
you can give it a quick boost before you head out and it will probably
tide you over for your run. With the Forerunner 15, there were numerous
times where I found it would run out of battery on longer runs. &lt;/p&gt;
&lt;h2 id="using-the-forerunner-35-on-linux"&gt;Using the Forerunner 35 on Linux&lt;/h2&gt;
&lt;p&gt;Much like the old Forerunner 15, this watch still works fairly well even
if you're not using Garmin's own software. That might be because you're
not keen on sharing your data or because you're on Linux and can't
easily run the software; the Windows version may run with WINE, however.&lt;/p&gt;
&lt;p&gt;Even if you don't use Garmin Connect, the watch gives you access to
everything you need as it appears as a USB storage device. You can
retrieve and apply GPS updates by &lt;a href="https://github.com/StevenMaude/armstrong"&gt;other
means&lt;/a&gt;; without a regular
update, GPS locking can be slow and take several minutes, as it did with
the Forerunner 15. It's also straightforward to copy the Garmin &lt;code&gt;.FIT&lt;/code&gt;
files from the watch and convert them to &lt;code&gt;.gpx&lt;/code&gt; with GPSBabel or
similar.&lt;/p&gt;
&lt;h2 id="maintenance"&gt;Maintenance&lt;/h2&gt;
&lt;p&gt;The two things that usually fail on digital watches are the strap and
the battery. The Forerunner 35 has a reasonably durable strap. And the
strap's replaceable: you can at least buy third-party replacements. The
battery is another matter: Garmin don't want you to replace the battery
in any of their watches at all — and I can't find any posts or videos on
doing so for the 35. However, if the Forerunner 35 is built like the
Forerunner 15, a battery replacement could be possible if you're willing
to take the watch apart.&lt;/p&gt;
&lt;p&gt;The battery replacement issue is one reason why I'm not inclined to
spend much more on specialist watches. You can easily spend two to four
times as much as the Forerunner 35 costs on more expensive Garmin
watches. I'm not sure how much value you get for spending more. For me,
the only significant features missing from this watch are directions to
follow a GPX route, and a swim mode. (That said, the Forerunner 35, like
the Forerunner 15, is waterproof). Neither of those omissions are enough
for me to spend considerably more. My primary use is tracking pacing and
distance while running, and the Forerunner 35 does well here.&lt;/p&gt;
&lt;h2 id="overall"&gt;Overall?&lt;/h2&gt;
&lt;p&gt;Whether you're looking at replacing an older, budget running watch, or
you've not ever had such a watch and want to try one out without
spending too much, the Forerunner 35 is a quietly competent choice. It's
been a substantial upgrade from the Forerunner 15, which I also liked a
lot.&lt;/p&gt;</content><category term="2020"></category><category term="Forerunner"></category><category term="Garmin"></category><category term="review"></category><category term="running"></category></entry></feed>