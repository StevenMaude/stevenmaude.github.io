<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>stevenmaude.co.uk</title><link href="https://www.stevenmaude.co.uk/" rel="alternate"></link><link href="https://www.stevenmaude.co.uk/feeds/all.atom.xml" rel="self"></link><id>https://www.stevenmaude.co.uk/</id><updated>2020-06-19T21:35:00+01:00</updated><entry><title>Oh, fork it</title><link href="https://www.stevenmaude.co.uk/posts/oh-fork-it" rel="alternate"></link><published>2020-06-19T21:35:00+01:00</published><updated>2020-06-19T21:35:00+01:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2020-06-19:/posts/oh-fork-it</id><summary type="html">&lt;p&gt;Why you should fork obscure, interesting repositories&lt;/p&gt;</summary><content type="html">&lt;h2 id="lost"&gt;Lost…&lt;/h2&gt;
&lt;p&gt;At work recently, I was trying to find a GitHub repository that I knew I
had previously seen a while back.&lt;/p&gt;
&lt;p&gt;But I couldn't find it.&lt;/p&gt;
&lt;p&gt;Normally, I would "star" possibly useful repositories: it wasn't in that
starred list. After spending a fair length of time trying to rediscover
the repository by many searches on GitHub and on search engines, I
concluded that maybe the author had simply deleted the repository or
their account.&lt;/p&gt;
&lt;p&gt;And so I gave up.&lt;/p&gt;
&lt;h2 id="and-found"&gt;…and found&lt;/h2&gt;
&lt;p&gt;Sometime later, while reading a related GitHub issue, I spotted I had
written a comment linking to the repository. It was still there, just
not easily discoverable.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id="lessons"&gt;Lessons&lt;/h2&gt;
&lt;p&gt;Things shared on the internet have no guarantee of longevity. You are
subject to the whims either of service providers either disappearing
entirely, or &lt;a href="https://www.stevenmaude.co.uk/posts/rinse-fms-soundcloud-account-takedown"&gt;removing a user and all their
content&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Users themselves may also delete things they've previously shared.
Especially in a post-GDPR world, where people are likely far aware of
their ability and rights to do just that.&lt;/p&gt;
&lt;p&gt;Even if I had starred the elusive repository, that would not have helped
if the user deleted the repository or the user's account disappeared.
For popular repositories, there is no likely threat of them vanishing
entirely overnight, because there are probably several existing forks.
And users may well restore a copy of such a deleted repository from
local clones.&lt;/p&gt;
&lt;p&gt;But if a repository is obscure, then that published version may be the
only source readily available.&lt;/p&gt;
&lt;p&gt;So, if there is some GitHub — or other online Git remote — repository
that looks interesting or useful, but is relatively obscure, then
forking it is prudent, and a one click operation without requiring you
to store a copy locally.&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;It may not be that often when people or organisations decide to delete
all their code, but it &lt;a href="https://www.theregister.com/2016/03/23/npm_left_pad_chaos/"&gt;does
happen&lt;/a&gt;.
Even if you may not necessarily have the final version before deletion,
something may be better than a distant memory.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;After all that effort, I actually decided to use a different
  approach anyway.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Of course, cloning locally is another valid approach, but requires
  you to store content that may just be clutter on your local storage.
  I'd wager if GitHub was to end their service, then there would be
  more than a day's notice.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="2020"></category><category term="GitHub"></category></entry><entry><title>"The Missing Semester of Your CS Education": a course review</title><link href="https://www.stevenmaude.co.uk/posts/the-missing-semester-of-your-cs-education-a-course-review" rel="alternate"></link><published>2020-06-07T20:55:00+01:00</published><updated>2020-06-07T20:55:00+01:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2020-06-07:/posts/the-missing-semester-of-your-cs-education-a-course-review</id><summary type="html">&lt;p&gt;A quick review and recommendation of a useful computer science
course&lt;/p&gt;</summary><content type="html">&lt;h2 id="missing-semester-singular"&gt;Missing semester: singular?&lt;/h2&gt;
&lt;p&gt;Though I have a science background, I don't have a formal computer
science education at all. In that sense then, a course entitled &lt;a href="https://missing.csail.mit.edu/"&gt;"The
Missing Semester of Your CS Education"&lt;/a&gt;
is an underestimation.&lt;/p&gt;
&lt;p&gt;In my case, they're &lt;em&gt;all&lt;/em&gt; missing semesters. (I'd love to learn more and
I do keep trying to learn what I can at work, and pick up new things in
my spare time.)&lt;/p&gt;
&lt;p&gt;But, looking over the course syllabus, I realised that, actually, I'd
already covered a fair amount of what it covers. Much of this had been
via learning at work, often from colleagues telling me about particular
tools. That actually sold the course to me: I was already aware that
some of the chosen topics were particularly useful. So, I figured, what
I didn't know might be worth knowing too.&lt;/p&gt;
&lt;p&gt;The central theme of the course is around the tooling that developers,
especially on Linux, might use while developing software, or working at
the command-line. The course covers: working with the command-line shell
and shell scripting, text editors, version control with Git, using
debugging and profiling tools, and a little introduction to
cryptographic tools.&lt;/p&gt;
&lt;h2 id="course-format"&gt;Course format&lt;/h2&gt;
&lt;p&gt;With eleven lectures of about an hour each, the course is well presented
and not too lengthy. The lecture notes available on the &lt;a href="https://missing.csail.mit.edu/"&gt;course
site&lt;/a&gt; are a useful reference and usually
fairly comprehensive. The notes don't always cover everything in the
lectures, particularly where there are worked examples. But, a skim
through the notes should give you a good impression of what's discussed,
if you prefer reading to videos.&lt;/p&gt;
&lt;h2 id="what-i-liked-about-the-course"&gt;What I liked about the course&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Many of the lectures are self-contained. There are a few that are
  easier to follow with some basic command-line shell knowledge, but
  that too is covered in the first couple of lectures.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Consequently, this means the course works well as a survey of topics.
  There is a little detail imparted to give you some deeper background,
  and sometimes other recommended readings. However, the level of
  presentation and the rate at which the material is worked through is
  very approachable without being overwhelming.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The exercises for each lecture apply the ideas covered in a very
  direct and practical way. Despite the problems being artificial, it is
  possible to envisage that you might solve real problems with similar
  approaches.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="do-i-recommend-it"&gt;Do I recommend it?&lt;/h2&gt;
&lt;p&gt;Yes, definitely. It will probably take about ten to twenty hours
covering this material, depending on whether you watch all the videos or
just read the notes. I should emphasise again that, even if you don't
want to go through the entire course, you can easily pick out the few
lectures that might interest you.&lt;/p&gt;
&lt;p&gt;I did learn a few things that I didn't know. And the exercises allowed
me to try working with some tools I hadn't used before (e.g. Linux
kernel cgroups).&lt;/p&gt;
&lt;p&gt;If you're an experienced Linux developer and constantly keep up-to-date
with tools, there may not be much new here. However, for developers
starting out, those who are starting to use Linux, those who are still
in education or those, like me, who think they might have some knowledge
gaps, this course is a nice compliment to other learning resources.&lt;/p&gt;</content><category term="2020"></category><category term="computer science"></category><category term="course"></category><category term="Linux"></category></entry><entry><title>Strange symptoms of hard drive enclosure failure</title><link href="https://www.stevenmaude.co.uk/posts/strange-symptoms-of-hard-drive-enclosure-failure" rel="alternate"></link><published>2020-05-09T21:35:00+01:00</published><updated>2020-05-09T21:35:00+01:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2020-05-09:/posts/strange-symptoms-of-hard-drive-enclosure-failure</id><summary type="html">&lt;p&gt;Describing some symptoms of a wonky hard drive enclosure on
Windows&lt;/p&gt;</summary><content type="html">&lt;h1 id="reliable-failure"&gt;Reliable failure&lt;/h1&gt;
&lt;p&gt;It's sometimes a reassuring comfort to know that computers and
computer-related things are entirely reliable. In that they are anything
but.&lt;/p&gt;
&lt;p&gt;As I spent about an hour looking into this problem, and now think it has
been fixed, perhaps it is helpful to document the symptoms such that
anyone searching might find this page and save them some time.
Especially if, like me, you don't have a spare enclosure to test with
and are thinking whether to buy a new one or not.&lt;/p&gt;
&lt;p&gt;(Yes, you probably should, is the answer, if you don't want to read
further.)&lt;/p&gt;
&lt;h1 id="some-background"&gt;Some background&lt;/h1&gt;
&lt;p&gt;My enclosure was a cheap and cheerful once with USB and eSATA ports.
eSATA is a bit dated these days, but is useful if you're working with
old PCs that don't have USB 3 ports.&lt;/p&gt;
&lt;h2 id="symptoms"&gt;Symptoms&lt;/h2&gt;
&lt;p&gt;There were different failure modes depending on how the drive was
connected:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When connected by USB, the drive was not recognised by Windows. That
  is, it did not show up in File Explorer when connected, as if it
  wasn't attached at all.&lt;/p&gt;
&lt;p&gt;In Disk Management, Windows was claiming the partition was a GPT
Protective Partition, whereas it was a real GPT partition, and
incorrectly had a size of 16,777,216 MB, i.e. the NTFS volume limit
with default cluster size, which was also incorrect.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When connected by eSATA, the drive was correctly recognised by
  Windows. Creating folders and, I think, copying moderate sized files
  apparently worked OK, though I didn't try reading the files back from
  the drive.&lt;/p&gt;
&lt;p&gt;However, running the Windows 7 Backup and Restore tool reliably caused
an error. Often, as soon as the backup process started to write to the
drive in the enclosure, the drive acted as if it had been
disconnected. That is, the backup failed, and the drive was no longer
visible in File Explorer.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="possible-causes"&gt;Possible causes?&lt;/h2&gt;
&lt;p&gt;As far as I could tell, there were three possibilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Something was wrong with Windows&lt;/strong&gt;. Not impossible, but this felt
  like more of a hardware fault, especially with the strange difference
  in behaviour between USB and eSATA, and with observed failures when
  different parts of Windows were running. It wasn't just the Backup and
  Restore tool that was failing, but Disk Cleanup had also caused the
  drive to disconnect.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The hard drive itself was failing&lt;/strong&gt;. Not impossible either, but
  unlikely. Though a magnetic disk, it is enterprise-grade and hadn't
  had much usage. In fact, the drive's SMART readings indicated a few
  hundred hours of time spent powered on.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Something was wrong with the enclosure&lt;/strong&gt;. Probably most likely,
  given the enclosure was inexpensive.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A cabling issue was ruled out on the basis that both USB and eSATA
weren't working, and had very different behaviour via the two
connections.&lt;/p&gt;
&lt;h2 id="closing-off-the-matter"&gt;Closing off the matter&lt;/h2&gt;
&lt;p&gt;In the end, not having a spare enclosure to test with, I bought a new
enclosure to try out. Out of curiosity, I chose one with both USB and
eSATA to test both out, in case the problem recurred.&lt;/p&gt;
&lt;p&gt;This did resolve part of the problem: the drive showed up both via eSATA
and USB in the new enclosure. On the other hand, the Windows 7 Backup
tool on Windows 10 was still failing. My hunch was that the faulty
enclosure had somehow got the drive into an odd state. I never figured
out what exactly the problem was here. A disk check did show errors,
though I can't remember whether those were able to be repaired, or
whether the drive disconnected while trying to do so. Maybe there was
some corruption of the file system?&lt;/p&gt;
&lt;p&gt;In the end, formatting the drive, encrypting the drive again and then
backing up finally resolved the — by-now very tedious — problem. So, not
all that exciting, but if you are witnessing similar symptoms, you can
probably fix it with a new enclosure.&lt;/p&gt;</content><category term="2020"></category><category term="hard drive"></category><category term="hardware"></category><category term="Windows"></category></entry><entry><title>A ULPS take: Windows 10 black screens and slow boot</title><link href="https://www.stevenmaude.co.uk/posts/a-ulps-take-windows-10-black-screens-and-slow-boot" rel="alternate"></link><published>2019-12-21T12:29:00+00:00</published><updated>2019-12-21T12:29:00+00:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2019-12-21:/posts/a-ulps-take-windows-10-black-screens-and-slow-boot</id><summary type="html">&lt;p&gt;Disabling ULPS on laptops that Windows 10 doesn't play nicely with.&lt;/p&gt;</summary><content type="html">&lt;h1 id="a-slow-boot-problem"&gt;A slow boot problem&lt;/h1&gt;
&lt;p&gt;Recently I was helping a friend with an older laptop running Windows 10
that seemed unusually slow to start.&lt;/p&gt;
&lt;p&gt;Though Windows seemed nimble once it started, the boot and shutdown
times felt excessively slow: minutes instead of the seconds it should
take. And it wasn't like Windows itself was doing anything in this state
either: the machine was silent, instead of the fans powering up, and
there was just a black screen following the Windows logo.&lt;/p&gt;
&lt;p&gt;Fortunately, with some frantic searching, I stumbled on a potential
solution: the cause might be a particular AMD graphics problem,
especially with two graphics cards, integrated and discrete. And the
laptop I was looking at did indeed have AMD Radeon hardware.&lt;/p&gt;
&lt;h1 id="ulps"&gt;ULPS&lt;/h1&gt;
&lt;p&gt;ULPS is an initialism used by AMD to refer to Ultra Low Power State, and
is the feature that can lead to this slow boot problem. As the name
suggests, this is a power saving feature.&lt;/p&gt;
&lt;p&gt;With the particular Windows install I was looking at, I didn't try
updating drivers beyond those that were automatically found by Windows
itself. However, reading around, the drivers may never have been fixed
for legacy hardware anyway.&lt;/p&gt;
&lt;h1 id="the-fix"&gt;The fix&lt;/h1&gt;
&lt;p&gt;The fix I found was to disable this ULPS feature in the registry.&lt;/p&gt;
&lt;p&gt;First, open the Windows Registry Editor. (In the Windows 10 search box,
search for "regedit" and then run "Registry Editor"; I can't remember,
but these edits may require you to be running the Registry Editor as
administrator, so you may need to right-click on "Registry Editor" and
then choose to run it as administrator.)&lt;/p&gt;
&lt;p&gt;Search for &lt;code&gt;EnableULPS&lt;/code&gt;, set any &lt;code&gt;1&lt;/code&gt; values to &lt;code&gt;0&lt;/code&gt;. There are also
&lt;code&gt;EnableULPS_NA&lt;/code&gt; settings but I read conflicting reports of whether to
set these to &lt;code&gt;0&lt;/code&gt; or not; in the end, only changing the &lt;code&gt;EnableULPS&lt;/code&gt;
settings was sufficient to resolve this issue for the laptop I was
working with.&lt;/p&gt;
&lt;p&gt;Hopefully, that should cure the problem. It's certainly a possibility
that subsequently installed graphics drivers could reset these overrides
and cause the symptom to recur, but, if that's the case, the problem is
easy to spot.&lt;/p&gt;
&lt;p&gt;After disabling ULPS, both booting and shutdown were much, &lt;em&gt;much&lt;/em&gt;
faster. The downside is that disabling ULPS may make the battery deplete
more rapidly than if it were enabled. But the boot up and shutdown times
were so slow without this fix that I think it's a necessary trade-off
to make your PC usable day-to-day, should you require it.&lt;/p&gt;
&lt;p&gt;There are other causes of a slow booting Windows installation, but if
you are dealing with a slow starting PC with Radeon graphics,
particularly with two display adapters, it's worth trying to update the
drivers and, failing that, seeing if this fix works.&lt;/p&gt;</content><category term="2019"></category><category term="Windows"></category></entry><entry><title>Learning from other projects: pelican-themes</title><link href="https://www.stevenmaude.co.uk/posts/learning-from-other-projects-pelican-themes" rel="alternate"></link><published>2019-12-16T22:41:00+00:00</published><updated>2019-12-16T22:41:00+00:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2019-12-16:/posts/learning-from-other-projects-pelican-themes</id><summary type="html">&lt;p&gt;Taking a look at pelican-themes — a project I currently use — to learn from it.&lt;/p&gt;</summary><content type="html">&lt;h2 id="lack-of-updates"&gt;Lack of updates&lt;/h2&gt;
&lt;p&gt;At the time of writing, this blog uses Pelican to convert the Markdown
blog content into publishable HTML. And, if you noticed from the dates
on my posts, there has been just over a year between the last post and
this one. This was mainly because there was considerable work needed to
get this blog setup up-to-date: both in upgrading Pelican to the latest
version, and pulling in updates to the theme.&lt;/p&gt;
&lt;p&gt;Updating the theme was made slightly more complicated by the migration
of the theme from its &lt;a href="https://github.com/DandyDev/pelican-bootstrap3"&gt;original
repository&lt;/a&gt;. The new
home became the
&lt;a href="https://github.com/getpelican/pelican-themes"&gt;pelican-themes&lt;/a&gt;
repository, not as a submodule but as the definitive repository for that
theme.&lt;/p&gt;
&lt;p&gt;In the past, it was simpler for me to simply pull request changes from
the parent of my theme's fork directly into my fork. Instead, I had to
restructure my repository slightly and start to &lt;code&gt;git cherry-pick&lt;/code&gt;
individual commits that were applied to the theme within the repository.&lt;/p&gt;
&lt;p&gt;Anyway, I've caught up on the maintenance. Bootstrap 3 is now
&lt;a href="https://blog.getbootstrap.com/2019/07/24/lts-plan/"&gt;end-of-life&lt;/a&gt; so
there is a longer term issue of this theme still being stuck on it. If I
end up migrating to a new theme, it might be worth investigating using
&lt;a href="https://gohugo.io/"&gt;Hugo&lt;/a&gt; instead of Pelican at the same time. Hugo has
increased in popularity considerably since I started using Pelican.&lt;/p&gt;
&lt;h2 id="learning-from-other-projects"&gt;Learning from other projects&lt;/h2&gt;
&lt;p&gt;While spending a fair amount of time updating my theme and working with
the pelican-themes repository, I had chance to think about how the
pelican-themes repository is structured and lessons I've learned just
from having to work with it.&lt;/p&gt;
&lt;p&gt;Reading and understanding — or at least attempting to understand —
other people's source code is a way of picking up new ideas or concepts.
What might also be useful for learning is looking at projects you use as
a whole. How are they organised? How does that makes them easy or
difficult to work with?&lt;/p&gt;
&lt;p&gt;There is a caveat that even a public source code repository doesn't
necessarily yield all the decision making that went on to get it to such
a state. Some of that process may indeed be located with the source
repository, e.g. pull request comment threads or issues. Some of that
process may be separate to the source repository, but still public, e.g.
public mailing lists. Some of that process may be entirely private, e.g.
emails or private working documents. Some of it may be undocumented at
all and reside entirely within maintainers' heads.&lt;/p&gt;
&lt;h2 id="pelican-themes"&gt;pelican-themes&lt;/h2&gt;
&lt;h3 id="a-note"&gt;A note&lt;/h3&gt;
&lt;p&gt;The tone of this post shouldn't be considered as a ranting "why, oh why,
is this project not doing things the way I suggest?" post, but primarily
an exercise to just consider and note other ways it could have been
structured.&lt;/p&gt;
&lt;p&gt;It's an actively maintained project, and the maintainers are
volunteering considerable amounts of their own time doing just that.&lt;/p&gt;
&lt;p&gt;In many projects, whether by a single developer or a team, whether
commercial and proprietary or open source, it's also entirely believable
that there's no long-term maintenance plan from the outset. At the
start, it's not even known whether the project will have a long-term
future. The first commit of pelican-themes was in February 2011, making
it nine years old in 2020. Often, things do just get worked out along
the way.&lt;/p&gt;
&lt;h3 id="the-current-state"&gt;The current state&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/getpelican/pelican-themes/"&gt;pelican-themes&lt;/a&gt; is a
mixture of submodules and themes whose files exist entirely in the
repository. The included non-submodule themes sometimes (if not often or
even always) use the pelican-themes repository as their definitive home.
There are a few problems I've seen with this approach, exemplified by
the theme I am currently using my &lt;a href="https://github.com/StevenMaude/pelican-bootstrap3-sm"&gt;own
fork&lt;/a&gt; of,
pelican-bootstrap3.&lt;/p&gt;
&lt;p&gt;Back when pelican-bootstrap3 was still maintained by its original
developer, there were actually changes made to the version in
&lt;a href="https://github.com/getpelican/pelican-themes/commit/c817f12a9f5034a05abec4d2515adabd003f9ac0#diff-32c97fb49ece91afc9f43c8405423109"&gt;pelican-themes&lt;/a&gt;
that diverged from pelican-bootstrap3. pelican-bootstrap3 within
&lt;a href="https://github.com/getpelican/pelican-themes/commit/faa85d6112a759767a4f327e35a07fa55d9e747e#diff-0eb6cb930365747af1fe070650593b8e"&gt;pelican-themes&lt;/a&gt;
was then updated by simply a straight copy over of the then-current
version of the upstream theme, losing the changes made to the
pelican-themes version. Apart from losing work, this process can be
potentially confusing for users not directly following the development
process; you can have something that was fixed, then &lt;em&gt;unfixed&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Later, the official home of pelican-bootstrap3 became the pelican-themes
repository as the original developer &lt;a href="https://github.com/getpelican/pelican-themes/pull/383"&gt;no longer wanted to support
it&lt;/a&gt;. This had a
couple of consequences.&lt;/p&gt;
&lt;p&gt;First, it meant that the pelican-themes maintainers adopted the extra
maintenance work of a popular theme. Those maintainers may not even
&lt;em&gt;use&lt;/em&gt; the theme. This means that pull requests can languish, perhaps
because the maintainers don't feel that comfortable merging substantial
changes or don't have strong opinions on whether the proposed changes
are worthwhile. For pelican-bootstrap3, at the time of writing in
December 2019, there are several unmerged pull requests on
pelican-themes right now, even as &lt;a href="https://github.com/getpelican/pelican-themes/pull/414"&gt;far back as
2016&lt;/a&gt;.  Pull
requests left unloved and unmerged are a deterrent to other developers
who may be considering contributing other changes.&lt;/p&gt;
&lt;p&gt;Second, even if pull requests are regularly merged, there may be less of
a definitive direction taken than if maintainers have strong opinions
about where that subproject is headed. It can also lead to a lack of
quality assurance. For pelican-bootstrap3, an example is this
&lt;a href="https://github.com/getpelican/pelican-themes/pull/441"&gt;translation
feature&lt;/a&gt;. Such a
feature is one that's useful to lots of people, but unfortunately it
&lt;a href="https://github.com/getpelican/pelican-themes/issues/460"&gt;broke things&lt;/a&gt;
for users who didn't have the same plugin configuration as the original
author, affecting those users who did not intend to use the new feature.&lt;/p&gt;
&lt;h3 id="how-else-might-pelican-themes-be-managed"&gt;How else might pelican-themes be managed?&lt;/h3&gt;
&lt;p&gt;That's how things are structured in pelican-themes now. I did think
about other ways the repository might have been structured taking the
above features of how it works right now into account.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;pelican-themes could simply have been a list of links to themes,
  solely a reference resource.&lt;/p&gt;
&lt;p&gt;The advantage of this is no management on the part of the
pelican-themes maintainers is required except to add new themes or
remove themes that are no longer supported or unavailable. In many
cases, once a theme is added, that would be as much as is ever
required to be done for that theme. The big disadvantage is that you
can't just clone the entire repository and have all the themes ready
to use. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There could be a "more strongly" monorepo version of what there is
  now, that is, pelican-themes could be a pure monorepo with no
  submodules.  This now means that &lt;em&gt;every theme&lt;/em&gt; has to be
  hand-maintained by copying from the upstream version repository, if
  pelican-themes isn't the original repository for a theme. This
  doesn't, however, solve the problem of having a mixture of maintained
  and unmaintained themes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Going completely in the opposite direction is an option too: have
  every theme in pelican-themes included as a submodule. This has the
  advantage that pull requests into pelican-themes would be simple,
  simply reflecting a submodule update to the parent repository's
  current release.&lt;/p&gt;
&lt;p&gt;It would mean that every theme in pelican-themes where
pelican-themes is the definitive repository for that theme would
need to be moved to its own individual repository. However, breaking
out the themes in this way might make it easier for those themes to
be managed by specific maintainers for each theme only (provided
volunteers could be found), as opposed to the current agglomerate
repository maintained by developers who may not use most of the
themes present.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course, the problems described above are easy to spot when using a
project that's been around a while, but perhaps subtle at a project's
inception. I think this is symptomatic of software development. It is
possible to build something that takes on a direction beyond that
originally envisaged, especially projects that have many contributors or
maintainers over time, each of which may have their own opinions as to
how such a project should be nurtured.&lt;/p&gt;</content><category term="2019"></category><category term="git"></category><category term="project management"></category></entry><entry><title>Stopping Fujitsu's Battery Charging Control Update Tool from crashing Windows 10</title><link href="https://www.stevenmaude.co.uk/posts/stopping-fujitsus-battery-charging-control-update-tool-from-crashing-windows-10" rel="alternate"></link><published>2018-12-10T21:16:00+00:00</published><updated>2018-12-10T21:16:00+00:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2018-12-10:/posts/stopping-fujitsus-battery-charging-control-update-tool-from-crashing-windows-10</id><summary type="html">&lt;p&gt;Preventing Fujitsu's Battery Charging Control Update from
making Windows 10 crash with a blue screen error caused by
tdklib64.sys.&lt;/p&gt;</summary><content type="html">&lt;p&gt;(NB: There's some background here just by way of introduction. If you encounter
this problem and don't want to endure my waffling, check the setting I &lt;a href="#the-fix"&gt;mention
below&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;My Fujitsu laptop currently dual boots Windows and Ubuntu, but it's rare that I
boot into Windows. Nonetheless, I had a little time spare last week, I figured
I might as well catch up on things everywhere and update the Windows install.&lt;/p&gt;
&lt;p&gt;Dropping into that did update Windows, and all well and good. Or so I thought.&lt;/p&gt;
&lt;h2 id="the-problem"&gt;The problem&lt;/h2&gt;
&lt;p&gt;On restarting, I noticed there was a Fujitsu prompt that appeared, and was a
little unexpected. What I was being asked to install was the very precisely
named "Battery Charging Control Update Tool". It seems &lt;a href="https://www.fujitsu.com/global/about/resources/news/notices/2018/1031-01.html"&gt;Fujitsu have had some
issues with battery
quality&lt;/a&gt;,
leading to a potential fire risk; this tool is supposed to mitigate that.&lt;/p&gt;
&lt;p&gt;It seems that, at least for my model of laptop, the tool was attempting to
update the BIOS. And you can see how the &lt;a href="https://www.fujitsu.com/hk/support/products/computing/pc/ap/announcements/battery-control-update-tool.html"&gt;tool &lt;em&gt;should&lt;/em&gt; work on Fujitsu's Hong
Kong site&lt;/a&gt;
(and that page I could only find on the Hong Kong site for some reason).&lt;/p&gt;
&lt;p&gt;In the previous paragraph, I say &lt;em&gt;attempting&lt;/em&gt; to update the BIOS, because what
happened, after the initial preparation stage occurred with the "Continue to
update BIOS?" prompt, was that shortly after I clicked "Yes", I saw a lovely
Windows 10 blue screen which I think mentioned tdklib64.sys as the cause.&lt;/p&gt;
&lt;p&gt;There's nothing I could find relating to this failed BIOS update and these blue
screens — although there were mentions of BIOS update failures and tdklib64.sys
relating to other manufacturers machines. Finding nothing struck me as strange:
it's a fair bet that you'll find at least one person's already complained
loudly somewhere about a problem you've encountered too. &lt;/p&gt;
&lt;p&gt;Anyway, I rebooted and tried the update again. Same result. Blue screen.&lt;/p&gt;
&lt;p&gt;OK then. Third time lucky, maybe? No. Just the same (reliably) unreliable
result.&lt;/p&gt;
&lt;h2 id="the-fix"&gt;The fix&lt;/h2&gt;
&lt;p&gt;In a moment of fortunate (and rare) inspiration, I remembered that I'd turned on a
relatively new security feature — &lt;a href="https://support.microsoft.com/en-us/help/4096339/windows-10-device-protection-in-windows-defender-security-center"&gt;Memory
Integrity&lt;/a&gt;
— in Windows Defender Security Center as I'd spotted it as a setting I'd not
enabled already. Perhaps that was the culprit, especially as no-one else seemed
to have encounter this failure yet?&lt;/p&gt;
&lt;p&gt;Yes. Yes, it was.&lt;/p&gt;
&lt;p&gt;Disabling that again meant the update proceeded without a problem, and then I
just re-enabled the Memory Integrity setting once again after the BIOS update
completed. If you're having a similar problem, check this setting before
attempting to update. Maybe this tip helps you avoid the hour I spent figuring
this out.&lt;/p&gt;</content><category term="2018"></category><category term="fix"></category><category term="Windows"></category></entry><entry><title>git: nice and lease-y</title><link href="https://www.stevenmaude.co.uk/posts/git-nice-and-lease-y" rel="alternate"></link><published>2018-11-10T13:23:00+00:00</published><updated>2018-11-10T13:23:00+00:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2018-11-10:/posts/git-nice-and-lease-y</id><summary type="html">&lt;p&gt;Why generally using &lt;code&gt;git push --force-with-lease&lt;/code&gt; over &lt;code&gt;git push --force&lt;/code&gt; seems sensible.&lt;/p&gt;</summary><content type="html">&lt;h2 id="can-you-feel-the-force"&gt;Can you feel the &lt;code&gt;--force&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;Force pushing to a remote repository that others may be using should
always be done with care. Even if it's a completely private repository
that only you use, you maybe should double check your thinking before
going ahead.&lt;/p&gt;
&lt;p&gt;The double edged sword of a force push is that you're changing the state
of the remote repository history irrevocably.&lt;/p&gt;
&lt;p&gt;This can be good, for instance, if you're working on a non-master
repository branch that you "own" and have perhaps cleaned it up:
rebasing it, removing or squashing unneeded separate commits.&lt;/p&gt;
&lt;p&gt;It can be bad if you force push to master on a repository, and cause, at
minimum, considerable inconvenience for other developers. Those
developesr may now face working out what exactly has happened to the
repository, when they try and integrate their future changes, or may be
baffled that a previously existing commit has now mysteriously
disappeared.&lt;/p&gt;
&lt;p&gt;If you're working on a non-master development branch, you may be a
little bit more lax in how you force push. Certainly, the way I've used
branches with other people is that generally a branch is owned by one
particular person, and those are free to be amended by that branch owner
(usually the creator of that branch, although ownership may be passed
from person to person). Then, as the agreed owner of such a branch,
provided I know that I'm happy with the local changes, I can just force
push to that development branch.&lt;/p&gt;
&lt;p&gt;However, that's not always the case. Perhaps two people are working on
the same branch, maybe working on slightly different things, e.g. one
could be working on frontend changes for the site, while another works
on backend changes, but these changes are part of the same feature, and
therefore need to be part of the same branch. &lt;/p&gt;
&lt;h2 id="what-force-with-lease-offers-over-vanilla-force"&gt;What &lt;code&gt;--force-with-lease&lt;/code&gt; offers over vanilla &lt;code&gt;--force&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;What I discovered recently, although it's been around for ages, is that
git has another option for forcing push: &lt;code&gt;--force-with-lease&lt;/code&gt;. What this
option does is checks that the remote branch is still in the same state
it was when you last pulled it, and refuses to force push if not, i.e.
there have been no other changes to the branch in the intervening time.&lt;/p&gt;
&lt;p&gt;Of course, you can always still override this check by just using plain
old &lt;code&gt;--force&lt;/code&gt;. But &lt;code&gt;--force-with-lease&lt;/code&gt; at least gives you another
safety check before force pushing, just in case someone else has altered
the remote branch (giving you chance, for example, to pull that branch,
and rebase your changes on it), and avoiding any confusion between
developers, and potentially loss of work.&lt;/p&gt;
&lt;p&gt;Note though, &lt;a href="https://stackoverflow.com/a/43726130"&gt;as this answer
highlights&lt;/a&gt;, if you have an editor
or other scheduled task running &lt;code&gt;git fetch&lt;/code&gt; in the background,
&lt;code&gt;--force-with-lease&lt;/code&gt; won't offer any protection as the remote tracking
branches that would be stored locally are being periodically updated.&lt;/p&gt;</content><category term="2018"></category><category term="git"></category></entry><entry><title>A look at Pipenv</title><link href="https://www.stevenmaude.co.uk/posts/a-look-at-pipenv" rel="alternate"></link><published>2018-08-26T14:06:00+01:00</published><updated>2018-08-26T14:06:00+01:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2018-08-26:/posts/a-look-at-pipenv</id><summary type="html">&lt;p&gt;A quick look at Pipenv, a tool to manage Python packages.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://github.com/pypa/pipenv"&gt;Pipenv&lt;/a&gt;&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; is a tool that aims to
remove the hassle of using
&lt;a href="https://www.stevenmaude.co.uk/posts/explaining-python-virtualenv-in-under"&gt;virtualenvs&lt;/a&gt;
(Python runtime environments to keep separate Python setups for
different projects independent), and also help manage requirements. It
also aims to help provide deterministic builds of software.&lt;/p&gt;
&lt;p&gt;I had read about Pipenv previously, but couldn't ever really understand
how it worked from just reading about it. So I switched from my existing
virtualenv setup to this to try it out and figure out whether I can
replicate the same behaviour I had with virtualenv and
virtualenvwrapper.&lt;/p&gt;
&lt;h2 id="differences"&gt;Differences&lt;/h2&gt;
&lt;p&gt;The main difference of Pipenv to the way you might work with virtualenvs
— which, for me, is switch to a particular virtualenv for a project, then
run commands in the shell as normal, just with a self-contained Python
setup — is that Pipenv is more contextual.&lt;/p&gt;
&lt;p&gt;With Pipenv, you change to the appropriate project directory and then
run commands directly in that virtualenv by preceding them with &lt;code&gt;pipenv
run&lt;/code&gt;, e.g. &lt;code&gt;pipenv run myscript.py&lt;/code&gt;. Pipenv knows which virtualenv to
use based on the location you're in.&lt;/p&gt;
&lt;p&gt;(You can also get more virtualenv-like behaviour by going to a project
directory and doing &lt;code&gt;pipenv shell&lt;/code&gt; where it effectively activates the
virtualenv in the shell. However, one downside with this is that the
subshell command history there only exists within that subshell; it is
not stored in your main shell.)&lt;/p&gt;
&lt;p&gt;Another difference is that you would also tend to favour using &lt;code&gt;pipenv&lt;/code&gt;
over &lt;code&gt;pip&lt;/code&gt; for installing packages; &lt;code&gt;pipenv install &amp;lt;SOME_PACKAGE&amp;gt;&lt;/code&gt; also
adds packages to your project's
&lt;a href="https://github.com/pypa/pipfile"&gt;&lt;code&gt;Pipfile&lt;/code&gt;&lt;/a&gt;, which replaces the older
&lt;code&gt;requirements.txt&lt;/code&gt; file of specifying dependencies.&lt;/p&gt;
&lt;h2 id="usage"&gt;Usage&lt;/h2&gt;
&lt;p&gt;You can create a new Pipenv either implicitly by &lt;code&gt;pipenv install --dev&lt;/code&gt;
which installs dependencies for that project (including dev
dependencies) in a new virtualenv it creates, or more explicitly by:
&lt;code&gt;pipenv --two&lt;/code&gt; or &lt;code&gt;pipenv --three&lt;/code&gt; which gets you a new virtualenv with
that version of Python.&lt;/p&gt;
&lt;p&gt;You can also use &lt;code&gt;--python &amp;lt;VERSION_NUMBER&amp;gt;&lt;/code&gt; to use a specific point
release of Python of your choice you have installed, e.g. 3.7.
Furthermore, if you have pyenv installed, it will install the requested
version of Python for you, if that version is not installed already.&lt;/p&gt;
&lt;p&gt;There are two broad uses of virtualenvs I had:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;for Python development to avoid any clash of package versions, which
   is covered quite well by the default behaviour of Pipenv.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for running standalone Python software I want to run, e.g.
   Docker Compose, but keeping their installations entirely independent
   of each other to avoid any conflicts. This isn't quite covered as
   well, because &lt;code&gt;pipenv run&lt;/code&gt; requires you to be in the directory or a
   subdirectory of that directory&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt; where you've already run Pipenv
   and a Pipfile exists, as that's how I assume it figures out which
   virtualenv to use. Otherwise, running Pipenv creates a new
   virtualenv! I think &lt;code&gt;pipenv shell&lt;/code&gt; works around this dropping you
   into a new subshell where the virtualenv is activated.&lt;/p&gt;
&lt;p&gt;Alternatively, in bash, you can do &lt;code&gt;source $(pipenv
--venv)/bin/activate&lt;/code&gt; in the directory with the virtualenv, to work
at a slightly lower level, with the virtualenv directly, without
&lt;code&gt;pipenv shell&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These use cases are both handled reasonably well by Pipenv.&lt;/p&gt;
&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;p&gt;Pipenv seems to work well enough if you want to simplify using
virtualenvs and management of dependencies. I think there are two groups
of users that it might particularly suit: those who are newer to
managing Python packaging and virtualenvs — as a means of abstracting
away virtualenv management — and those who are more experienced but want
to have a tool that integrates other features, e.g. checking for
dependency vulnerabilities via &lt;code&gt;pipenv check&lt;/code&gt; (which is provided by the
&lt;a href="https://github.com/pyupio/safety"&gt;safety&lt;/a&gt; package).&lt;/p&gt;
&lt;p&gt;However, if you read around, there is still some contention about Pipenv
being &lt;a href="https://packaging.python.org/guides/tool-recommendations/"&gt;recommended by the
PyPA&lt;/a&gt;.
Certainly, there are a considerable number of small issues that remove
some of Pipenv's sheen; &lt;a href="https://github.com/pypa/pipenv/issues/2753"&gt;I encountered a small one already
reported&lt;/a&gt; within just a
short time of using Pipenv. There are also several issues relating to
dependency resolution, which seem a little more critical seeing as
dependency management is one of the tool's core goals.&lt;/p&gt;
&lt;p&gt;Pipenv then is no panacea for Python's still byzantine dependency
management. &lt;a href="https://www.python.org/dev/peps/pep-0020/"&gt;PEP 20&lt;/a&gt;'s call
for "one obvious way to do it" is not yet fully heeded. But maybe it's a
step roughly in the right direction, even if there's still some
meandering to do before there's a really simple and transparent workflow
for Python. (However, I don't think it's uncommon for dependency
management being tricky to get right either; Go has been around for a
decade and is only just &lt;a href="https://blog.golang.org/versioning-proposal"&gt;getting
there&lt;/a&gt;. Python's had
considerably longer than Go to get it right though.)&lt;/p&gt;
&lt;p&gt;Finally, it is worth noting that there are other alternatives too.
&lt;a href="https://github.com/sdispater/poetry"&gt;Poetry&lt;/a&gt; is a newer, and perhaps
less well known, tool whose goals intersect with those of Pipenv. It
fixes some of the existing issues of dependency resolution that
pip-tools has (pip-tools is the underlying package that pipenv actually
uses for this task), and therefore may be another useful contender to
keep in mind.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Confusingly, Pipenv's name is capitalised, while pip's is not.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Caveat: it only looks a certain number of subdirectories deep by
default, though &lt;a href="https://github.com/pypa/pipenv/issues/1634"&gt;this number is configurable&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="2018"></category><category term="Pipenv"></category><category term="Python"></category></entry><entry><title>Solve your problem with sloppy Python</title><link href="https://www.stevenmaude.co.uk/posts/solve-your-problem-with-sloppy-python" rel="alternate"></link><published>2018-05-20T17:24:00+01:00</published><updated>2018-05-20T17:24:00+01:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2018-05-20:/posts/solve-your-problem-with-sloppy-python</id><summary type="html">&lt;p&gt;A summary of a talk by Larry Hastings at PyCon 2018.&lt;/p&gt;</summary><content type="html">&lt;h2 id="pycon-2018-a-quick-note"&gt;PyCon 2018: A quick note&lt;/h2&gt;
&lt;p&gt;As PyCon 2018 happened last week, I've been watching a few talks. It's
sometimes difficult to keep up with changes to technology if you're not
paying constant attention. These kinds of talks are a useful way of
trying to catch up a little. With that in mind, I'm writing up summaries
of a few talks here.&lt;/p&gt;
&lt;h2 id="solve-your-problem-with-sloppy-python"&gt;Solve your problem with sloppy Python&lt;/h2&gt;
&lt;p&gt;The talk is available to &lt;a href="https://www.youtube.com/watch?v=Jd8ulMb6_ls"&gt;watch
here&lt;/a&gt;, and an easy watch.
This was a pragmatic and enjoyable talk that would be easy for beginners
in Python to follow.&lt;/p&gt;
&lt;p&gt;It's a nice contrast from other programming talks too. Often,
presenters, quite reasonably, focus on telling or teaching an audience
what they believe to be best practice on a topic. Concentrating on a
more practical side made for a light and refreshing approach.&lt;/p&gt;
&lt;h3 id="code-being-discussed-is-for-personal-automation"&gt;Code being discussed is for personal automation&lt;/h3&gt;
&lt;p&gt;Writing code to solve your problem.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Not writing code in a professional context.&lt;/li&gt;
&lt;li&gt;These are throwaway scripts.&lt;/li&gt;
&lt;li&gt;You're the only person writing it and likely to see it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="rules"&gt;Rules&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Fail early and noisily.&lt;/li&gt;
&lt;li&gt;Use Python instead of shell scripts.&lt;/li&gt;
&lt;li&gt;Have fun!&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="guidelines"&gt;Guidelines&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Use latest Python version to take advantage of new features.&lt;/li&gt;
&lt;li&gt;Try automating even more, push as far as you can go, but may have some
  human intervention too.&lt;/li&gt;
&lt;li&gt;These projects are an excuse to try or learn new libraries/technologies.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It doesn't matter if the code's hacky; you may not bother with tests.
Quick and dirty code to get a job done. A couple of examples of this
from the renaming files problem in the talk:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;using &lt;code&gt;ls&lt;/code&gt; to generate a list of filenames in Python; add triple
  quotes around string, &lt;code&gt;strip()&lt;/code&gt; and &lt;code&gt;split()&lt;/code&gt; on newlines gives a
  list.&lt;/li&gt;
&lt;li&gt;using exceptions lists in renaming files (e.g. to add apostrophes to
  words), run through each check for each filename. Most won't trigger,
  so you're doing lots of unnecessary checks, and could refine that, but
  performance unlikely to be an issue for these kinds of tasks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cutting corners is OK in this context, if it gets the job done.&lt;/p&gt;
&lt;h3 id="example-uses"&gt;Example uses&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Renaming files. A general tip for file renaming tasks — in this case,
  downloaded radio shows — back these up via creating hard links with
  the same filenames in a backup directory. That way you can always
  revert to the original names, without having to backup the files.
  Could use Python's &lt;code&gt;os.link()&lt;/code&gt; but also possible via a simple shell
  loop: &lt;code&gt;mkdir backup &amp;amp;&amp;amp; for a in * ; do ln $a backup/$a ; done&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Provisioning new machines, e.g. running &lt;code&gt;apt install&lt;/code&gt; and configuring
  programs, e.g. copying license keys.&lt;/li&gt;
&lt;li&gt;Tidying audio files, creating playlists etc.; possibly with human
  intervention here.&lt;/li&gt;
&lt;li&gt;Ripping CDs, using simple metadata format that can be parsed easily.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="a-final-note"&gt;A final note&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Sometimes Python was used to call out to the shell. &lt;code&gt;subprocess.run(s,
  check=True, shell=True)&lt;/code&gt; is better than &lt;code&gt;os.system()&lt;/code&gt; because
  &lt;code&gt;os.system()&lt;/code&gt; does not fail noisily, but &lt;code&gt;subprocess.run()&lt;/code&gt; does.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="a-thought"&gt;A thought&lt;/h3&gt;
&lt;p&gt;One thing that didn't get asked in the Q&amp;amp;A at the end: how should you
estimate whether the automation is actually costing you time? xkcd
has covered this well in these &lt;a href="https://xkcd.com/1205/"&gt;two&lt;/a&gt;
&lt;a href="https://xkcd.com/1319/"&gt;comics&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In some cases, it can be reasonably predicted that, if the process is
either time consuming or will be repeated often, it's worthwhile to
spend the time to write code as a solution to the problem.&lt;/p&gt;
&lt;p&gt;But, the "Rogue's Gallery" radio show renaming given as the main example
presumably took a few minutes to write, find the exceptions (by hand)
and verify (probably also by hand) the code is doing what it should.
There are only actually a few shows to rename, and these themselves
could be done by hand, as a one-off task.&lt;/p&gt;</content><category term="2018"></category><category term="PyCon"></category><category term="Python"></category></entry><entry><title>Upgrading Raspbian and rc.local failures</title><link href="https://www.stevenmaude.co.uk/posts/upgrading-raspbian-and-rclocal-failures" rel="alternate"></link><published>2017-12-10T20:13:00+00:00</published><updated>2017-12-10T20:13:00+00:00</updated><author><name>Steven Maude</name></author><id>tag:www.stevenmaude.co.uk,2017-12-10:/posts/upgrading-raspbian-and-rclocal-failures</id><summary type="html">&lt;p&gt;Using a Raspberry Pi as a wireless bridge, in-place upgrading Raspbian
and dealing with &lt;code&gt;rc.local&lt;/code&gt; not running tasks as planned.&lt;/p&gt;</summary><content type="html">&lt;h2 id="a-raspberry-pi-as-a-wireless-bridge-for-old-hardware"&gt;A Raspberry Pi as a wireless bridge for old hardware&lt;/h2&gt;
&lt;p&gt;This is something I did a couple of months back, but figure it's worth
documenting, to maybe help anyone with a similar problem search for it.&lt;/p&gt;
&lt;p&gt;One use for my Raspberry Pi is as a wireless bridge, and this is mainly
for a now ancient Xbox 360. Yes, the one without built-in wifi, it just
has an Ethernet port for networking; not much good when your router is
nowhere near a TV.&lt;/p&gt;
&lt;p&gt;Originally, and as is often customary when solving technology problems,
I used &lt;a href="https://unix.stackexchange.com/a/64353/32125"&gt;instructions that I cobbled
together&lt;/a&gt; from various
places.&lt;/p&gt;
&lt;p&gt;I'd been slack on upgrading my Raspberry Pi's Raspbian. It was working
perfectly fine for what it was doing, so there was no immediate need to
touch it. Because of this, it has languished on a distribution based on
the now aging Debian Wheezy.&lt;/p&gt;
&lt;p&gt;More recently, with the &lt;a href="https://www.ncsc.gov.uk/krack"&gt;recent WPA2
exploit&lt;/a&gt; in October, and the then lack of
any as-yet patch even for Debian Wheezy (which has since been patched,
not sure about Raspbian itself), I thought I should finally upgrade, so
the Pi was patched against this and any other future security issues.&lt;/p&gt;
&lt;p&gt;I didn't particularly want to go to the trouble of doing a fresh
install, so I tried an in-place operating system upgrade, deciding that
the worst that could happen is the upgrade fails and I'd have to do a
fresh install anyway.&lt;/p&gt;
&lt;h2 id="the-upgrade-process"&gt;The upgrade process&lt;/h2&gt;
&lt;p&gt;I actually upgraded in two stages. First from Wheezy to Jessie, and then
I figured if that went OK, I could try upgrading again, from Jessie to
Stretch too.&lt;/p&gt;
&lt;p&gt;Upgrading the distribution actually worked well. With my Raspbian Wheezy
install, I upgraded to Jessie as described on the &lt;a href="https://www.raspberrypi.org/forums/viewtopic.php?f=66&amp;amp;t=121880"&gt;Raspberry Pi
forum&lt;/a&gt;.
Everything seemed to work, including the Xbox's internet connection.&lt;/p&gt;
&lt;p&gt;Since I was feeling brave, I decided to upgrade again. However, I didn't
feel so brave that I would do that without first backing up the working
system, so I &lt;a href="https://raspberrypi.stackexchange.com/a/312/12370"&gt;backed up the SD card with
&lt;code&gt;dd&lt;/code&gt;&lt;/a&gt; to a gzipped
image in case something went wrong and I could recover a working system
quickly.&lt;/p&gt;
&lt;p&gt;Next, I upgraded from Jessie to Stretch. This is the same process as for
Wheezy to Jessie, just with &lt;a href="https://www.raspberrypi.org/blog/raspbian-stretch/"&gt;different repository sources
used&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once again, the upgrade worked fine, the Pi booted up, and I could
connect to it wirelessly.&lt;/p&gt;
&lt;h2 id="a-stretch-too-far"&gt;A stretch too far&lt;/h2&gt;
&lt;p&gt;But, the Xbox's internet connection no longer worked. Checking the Pi, I
spotted what looked like error messages appearing at boot time.&lt;/p&gt;
&lt;p&gt;The first problem is checking the boot log messages that quickly
disappear from the screen. Since Debian now uses systemd, you need &lt;code&gt;sudo
systemctl&lt;/code&gt; to review those messages.&lt;/p&gt;
&lt;p&gt;What I spotted there is that there was an error that indicated that
commands I had in &lt;code&gt;rc.local&lt;/code&gt; were not running correctly. As mentioned,
in my &lt;a href="https://unix.stackexchange.com/a/64353/32125"&gt;description of my Xbox and Pi
configuration&lt;/a&gt;, I was
using &lt;code&gt;rc.local&lt;/code&gt; to run the commands on boot that ensured the bridge
worked, instead of having to run anything by hand every boot.&lt;/p&gt;
&lt;p&gt;That seemed strange. More so when running the script by hand caused it
to work as normal, which allowed the Xbox to once again connect to the
internet as it did on Raspbian Jessie.&lt;/p&gt;
&lt;p&gt;Why did this script fail on boot via &lt;code&gt;rc.local&lt;/code&gt;? As &lt;a href="https://www.raspberrypi.org/forums/viewtopic.php?f=66&amp;amp;t=122207"&gt;mentioned on the
Raspberry Pi
forums&lt;/a&gt;,
the difference presumably is that the Pi's networking isn't configured
at the time of the script trying to run. Trying to then change this
configuration when it's not ready will then fail.&lt;/p&gt;
&lt;p&gt;So there are no guarantees about when &lt;code&gt;rc.local&lt;/code&gt; is run. If you have
dependencies on other things, the moral of this longish story is that
you should create a systemd service and have systemd launch it after
everything else; this fixed the problem and everything finally was
working again.&lt;/p&gt;
&lt;h2 id="configuration"&gt;Configuration&lt;/h2&gt;
&lt;p&gt;For reference, here's what I have configured:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;wireless_bridge.sh&lt;/code&gt; is saved in &lt;code&gt;/usr/local/sbin&lt;/code&gt;, with 755 file
permissions, root as owner and group, and contains:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/sh -e&lt;/span&gt;
/usr/sbin/ifplugd eth0 --kill
/sbin/sysctl -w net.ipv4.ip_forward&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
/sbin/ifconfig eth0 &lt;span class="m"&gt;192&lt;/span&gt;.168.1.1
/sbin/iptables -t nat -A POSTROUTING -o wlan0 -s &lt;span class="m"&gt;192&lt;/span&gt;.168.1.0/24 -j MASQUERADE
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;wireless-bridge.service&lt;/code&gt; is saved in &lt;code&gt;/etc/systemd/system&lt;/code&gt;, with 644
file permissions, root as owner and group, and contains:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[Unit]&lt;/span&gt;
&lt;span class="na"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Wireless Bridge Service&lt;/span&gt;
&lt;span class="na"&gt;After&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;multi-user.target&lt;/span&gt;

&lt;span class="k"&gt;[Service]&lt;/span&gt;
&lt;span class="na"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;idle&lt;/span&gt;
&lt;span class="na"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/usr/local/sbin/wireless_bridge.sh&lt;/span&gt;

&lt;span class="k"&gt;[Install]&lt;/span&gt;
&lt;span class="na"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;multi-user.target&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You could possibly change &lt;code&gt;multi-user.target&lt;/code&gt; to one of systemd's
&lt;a href="https://www.freedesktop.org/wiki/Software/systemd/NetworkTarget/"&gt;network
targets&lt;/a&gt;,
but I didn't bother testing this out, as the configuration above just
seemed to work (with, I suppose, the possible cost of the bridged
connection not being available until slightly later).&lt;/p&gt;
&lt;p&gt;I also have the Xbox network settings as:&lt;/p&gt;
&lt;p&gt;IP address: 192.168.1.2&lt;br&gt;
Subnet mask: 255.255.255.0&lt;br&gt;
Gateway: 192.168.1.1  &lt;/p&gt;
&lt;p&gt;and the primary DNS server set to my router's IP address.&lt;/p&gt;</content><category term="2017"></category><category term="Raspberry Pi"></category><category term="Raspbian"></category><category term="Linux"></category></entry></feed>